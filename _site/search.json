[
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "#1. Overview"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#background-human-mobility-the-movement-of-human-beings-in-space-and-time-reflects-the-spatial-temporal-characteristics-of-human-behavior.-with-the-advancement-information-and-communication-technologies-ict-especially-smart-phone-a-large-volume-of-data-related-to-human-mobility-have-been-collected.-by-using-appropriate-gis-analysis-methods-these-data-are-potentially-useful-in-supporting-smart-city-planning-and-management.",
    "href": "Take-home_Ex01/Take-home_Ex01.html#background-human-mobility-the-movement-of-human-beings-in-space-and-time-reflects-the-spatial-temporal-characteristics-of-human-behavior.-with-the-advancement-information-and-communication-technologies-ict-especially-smart-phone-a-large-volume-of-data-related-to-human-mobility-have-been-collected.-by-using-appropriate-gis-analysis-methods-these-data-are-potentially-useful-in-supporting-smart-city-planning-and-management.",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "1.1 Background Human mobility, the movement of human beings in space and time, reflects the spatial-temporal characteristics of human behavior. With the advancement Information and Communication Technologies (ICT) especially smart phone, a large volume of data related to human mobility have been collected. By using appropriate GIS analysis methods, these data are potentially useful in supporting smart city planning and management.",
    "text": "1.1 Background Human mobility, the movement of human beings in space and time, reflects the spatial-temporal characteristics of human behavior. With the advancement Information and Communication Technologies (ICT) especially smart phone, a large volume of data related to human mobility have been collected. By using appropriate GIS analysis methods, these data are potentially useful in supporting smart city planning and management.\nIn Singapore, one of the important source of data related to human mobility is from Land Transport Authority (LTA) DataMall. Two data sets related to human mobility are provided by the portal, they are: Passenger Volume by Origin Destination Train Stations and Passenger Volume by Origin Destination Bus Stops. One of the limitation of these data sets is that their location are biased to either bus stops or MRT/LRT stations. In 2020, another very interesting human mobility data set called Grab Posisi was released by GRAB, one of the largest shared taxi operator in South-east Asia. There are two data sets been released and one of them is for Singapore."
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate spatial point patterns analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore."
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#tasks",
    "href": "Take-home_Ex01/Take-home_Ex01.html#tasks",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "1.3 Tasks",
    "text": "1.3 Tasks\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer in sf tibble data.frames:\n\nGrab taxi location points either by origins or destinations.\nRoad layer within Singapore excluding outer islands.\nSingapore boundary layer excluding outer islands\n\nUsing the extracted data, derive traditional Kernel Density Estimation layers.\nUsing the extracted data, derive either Network Kernel Density Estimation (NKDE) or Temporal Network Kernel Density Estimation (TNKDE)\nUsing appropriate tmap functions, display the kernel density layers on openstreetmap of Singapore.\nDescribe the spatial patterns revealed by the kernel density maps."
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#loading-datasets",
    "href": "Take-home_Ex01/Take-home_Ex01.html#loading-datasets",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.1 Loading datasets",
    "text": "3.1 Loading datasets\n\n3.1.1 Grab-Posisi\nWe can load all the Grab-Posisi datasets with this code chunk:\n\nfile_list &lt;- list.files('./data/GrabPosisi')\n\ncombined &lt;- list()\nfor(i in seq(file_list)) {\n  data_name &lt;- paste0('grabposisi', i - 1)\n  temp &lt;- read_parquet(paste0('data/GrabPosisi/', file_list[i]))\n  combined[[i]] &lt;- temp\n}\n\ngrabposisi &lt;- bind_rows(combined)\n\nWhat the code chunk above does, is that it takes in the names of the files in the specified folder, turning it into a list.\nNow, we explore the grabposisi data\n\nglimpse(grabposisi)\n\nRows: 30,329,685\nColumns: 9\n$ trj_id        &lt;chr&gt; \"70014\", \"73573\", \"75567\", \"1410\", \"4354\", \"32630\", \"646…\n$ driving_mode  &lt;chr&gt; \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", …\n$ osname        &lt;chr&gt; \"android\", \"android\", \"android\", \"android\", \"android\", \"…\n$ pingtimestamp &lt;int&gt; 1554943236, 1555582623, 1555141026, 1555731693, 15555844…\n$ rawlat        &lt;dbl&gt; 1.342326, 1.321781, 1.327088, 1.262482, 1.283799, 1.3003…\n$ rawlng        &lt;dbl&gt; 103.8890, 103.8564, 103.8613, 103.8238, 103.8072, 103.90…\n$ speed         &lt;dbl&gt; 18.910000, 17.719076, 14.021548, 13.026521, 14.812943, 2…\n$ bearing       &lt;int&gt; 248, 44, 34, 181, 93, 73, 82, 321, 324, 31, 203, 50, 252…\n$ accuracy      &lt;dbl&gt; 3.900, 4.000, 3.900, 4.000, 3.900, 3.900, 3.000, 3.649, …\n\n\nWe noticed that pingtimestamp is an integer field, so we need to convert pingtimestamp field to a datetime format (POCIXCT)\n\ngrabposisi$pingtimestamp &lt;- as_datetime(grabposisi$pingtimestamp)\n\n\n3.1.1.1 Origin\nNow, we can extract the origin of a ride, based on trajectory id. We will group the rows based on trajectory id, and sort it in ascending order based on the timestamp. The first index of every trajectory id will be the starting point of that ride. After the extraction, we can use use st_as_sf() to convert it into an sf, with the parameter crs=4326 as the dataset is taken from GPS data, which typically uses the WGS-84. However, we need to use st_transform to set the crs to 3414, which is used in Singapore.\n\nsetDT(grabposisi)\n\ngrabposisi[, `:=`(\n  weekday = wday(pingtimestamp),\n  starting_hour = factor(hour(pingtimestamp)),\n  day = factor(mday(pingtimestamp))\n)]\n\norigin &lt;- grabposisi[order(trj_id, pingtimestamp)\n  ][, .SD[1], by = .(trj_id)\n  ] |&gt; st_as_sf(coords=c(\"rawlng\", \"rawlat\"), crs=4326) |&gt; st_transform(3414)\n\nst_crs(origin)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nLet’s filter so that we only have cars in the data\n\norigin &lt;- filter(origin, driving_mode == 'car')\n\nNow, we can see what it looks like\n\nqtm(origin)\n\n\n\n\n\n\n3.1.1.2 Destination\nWe can apply a similar logic to get the destination. The difference is that we need to sort it in descending order based on the timestamp.\n\nsetDT(grabposisi)\n\ngrabposisi[, `:=`(\n  weekday = wday(pingtimestamp),\n  starting_hour = factor(hour(pingtimestamp)),\n  day = factor(mday(pingtimestamp))\n)]\n\ndestination &lt;- grabposisi[order(trj_id, -pingtimestamp)\n  ][, .SD[1], by = .(trj_id)\n  ] |&gt; st_as_sf(coords=c(\"rawlng\", \"rawlat\"), crs=4326) |&gt; st_transform(3414)\n\nst_crs(destination)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nSame as above, we can filter it\n\ndestination &lt;- filter(destination, driving_mode == 'car')\n\nAnd plot it\n\nqtm(destination)\n\n\n\n\n\n\n\n3.1.2 Geospatial Data\n\n3.1.2.1 MPSZ\nNow, we need to load the geospatial data. Let’s start with the 2019 Subzone Master Plan\n\nmpsz2019_sf &lt;- st_read(dsn='data/Geospatial/MPSZ-2019', layer='MPSZ-2019') |&gt; st_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Take-home_Ex01\\data\\Geospatial\\MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nst_crs(mpsz2019_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nAnd see what it looks like on a plot.\n\nqtm(mpsz2019_sf)\n\n\n\n\nNotice that this includes the surrounding islands. To extract only the main island, we can filter out the surrounding islands with this code chunk below. The !grepl() function will find any of the rows that doesn’t include “ISLAND” in their PLN_AREA_N column. You can see the difference between the plots\nNotice that this includes the surrounding islands. To extract only the main island, we can filter out the surrounding islands with this code chunk below\n\nmpsz2019_sf &lt;- mpsz2019_sf[!grepl(\"ISLAND\", mpsz2019_sf$PLN_AREA_N, ignore.case = TRUE), ]\nqtm(mpsz2019_sf)\n\n\n\n\nNow, we can get the outline of Singapore’s main island with st_union()\n\nsg_sf &lt;- mpsz2019_sf |&gt; st_union()\nplot(sg_sf)\n\n\n\n\n\n\n3.1.2.2 Road Data\nAfter the Master Plan, we can move on to the Road Data Set\n\nroad_sf &lt;- st_read(dsn = 'data/Geospatial/malaysia-singapore-brunei-latest-free.shp', layer='gis_osm_roads_free_1') |&gt; st_transform(crs=3414)\n\nReading layer `gis_osm_roads_free_1' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Take-home_Ex01\\data\\Geospatial\\malaysia-singapore-brunei-latest-free.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1765176 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 99.66041 ymin: 0.8021131 xmax: 119.2601 ymax: 7.514393\nGeodetic CRS:  WGS 84\n\nst_crs(road_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nglimpse(road_sf)\n\nRows: 1,765,176\nColumns: 11\n$ osm_id   &lt;chr&gt; \"4386520\", \"4578273\", \"4579495\", \"4579533\", \"4579534\", \"45795…\n$ code     &lt;int&gt; 5113, 5114, 5122, 5122, 5122, 5122, 5141, 5122, 5122, 5122, 5…\n$ fclass   &lt;chr&gt; \"primary\", \"secondary\", \"residential\", \"residential\", \"reside…\n$ name     &lt;chr&gt; \"Orchard Road\", \"Jalan Bukit Bintang\", \"Jalan Nagasari\", \"Per…\n$ ref      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ oneway   &lt;chr&gt; \"F\", \"F\", \"B\", \"B\", \"B\", \"F\", \"F\", \"F\", \"F\", \"F\", \"B\", \"B\", \"…\n$ maxspeed &lt;int&gt; 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 0, 0,…\n$ layer    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ bridge   &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"…\n$ tunnel   &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"T\", \"F\", \"F\", \"F\", \"F\", \"F\", \"…\n$ geometry &lt;LINESTRING [m]&gt; LINESTRING (27637.52 32038...., LINESTRING (-20666…"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#converting-to-ppp",
    "href": "Take-home_Ex01/Take-home_Ex01.html#converting-to-ppp",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.2 Converting to PPP",
    "text": "3.2 Converting to PPP\nSince KDE requires the point data to be in ppp format, we will convert our origin and destination to ppp. To do this, we can convert it into a Spatial* object with as_Spatial(), then to an sp object with as(x, ‘SpatialPoints’), then finally to ppp with as(x, ‘ppp’)\n\norigin_spatial &lt;- as_Spatial(origin)\norigin_sp &lt;- as(origin_spatial, 'SpatialPoints')\norigin_ppp &lt;- as(origin_sp, 'ppp')\n\ndestination_spatial &lt;- as_Spatial(destination)\ndestination_sp &lt;- as(destination_spatial, 'SpatialPoints')\ndestination_ppp &lt;- as(destination_sp, 'ppp')\n\n#Alternatively, we can also use the commented codes below to directly convert to ppp\n# origin_ppp &lt;- as.ppp(origin)\n# destination_ppp &lt;- as.ppp(destination)\n\nPlot it to see how it looks like\n\nplot(origin_ppp)\n\n\n\nplot(destination_ppp)\n\n\n\n\nWe can check for duplicates\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\nany(duplicated(destination_ppp))\n\n[1] FALSE\n\n\nSince both origin_ppp and destination_ppp doesn’t have duplicates, we can move on to the next step"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#converting-to-owin-object",
    "href": "Take-home_Ex01/Take-home_Ex01.html#converting-to-owin-object",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.3 Converting to OWIN Object",
    "text": "3.3 Converting to OWIN Object\nWe need to convert our sg_sf, which is the Singapore main island’s outline, to an OWIN object\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "href": "Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.5 Combining point events object and OWIN object",
    "text": "3.5 Combining point events object and OWIN object\nBefore performing the analysis, we need to extract only points that are inside Singapore’s main island\n\norigin_sg &lt;- origin_ppp[sg_owin]\ndestination_sg &lt;- destination_ppp[sg_owin]\n\nConvert it to use kilometres as units, since what we have now is in terms of metres\n\norigin_sg_km &lt;- rescale(origin_sg, 1000, 'km')\ndestination_sg_km &lt;- rescale(destination_sg, 1000, 'km')"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.1 First Order Spatial Point Patterns Analysis",
    "text": "4.1 First Order Spatial Point Patterns Analysis\n\n4.1.1 KDE with automatic bandwith selection method\nWe will compare computations using these method: - bw.diggle() - bw.CvL() - bw.scott() - bw.ppl()\n\nOrigin\n\nkde_origin_diggle &lt;- density(origin_sg_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_origin_cvl &lt;- density(origin_sg_km,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\n\nkde_origin_scott &lt;- density(origin_sg_km,\n                              sigma=bw.scott,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\n\nkde_origin_ppl &lt;- density(origin_sg_km,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nNow we can see the plot for comparison\n\npar(mfrow=c(2,2))\nplot(kde_origin_diggle, main = \"bw.diggle\")\nplot(kde_origin_cvl, main = \"bw.cvl\")\nplot(kde_origin_scott, main = \"bw.scott\")\nplot(kde_origin_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\nDestination\n\nkde_destination_diggle &lt;- density(destination_sg_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_destination_cvl &lt;- density(destination_sg_km,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_destination_scott &lt;- density(destination_sg_km,\n                              sigma=bw.scott,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_destination_ppl &lt;- density(destination_sg_km,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nNow we can see the plot for comparison\n\npar(mfrow=c(2,2))\nplot(kde_destination_diggle, main = \"bw.diggle\")\nplot(kde_destination_cvl, main = \"bw.cvl\")\nplot(kde_destination_scott, main = \"bw.scott\")\nplot(kde_destination_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n4.1.2 Adaptive Bandwidth KDE\nThe issue about fixed bandwidth is that less crowded areas, such as countrysides, tends to be less dense compared to more crowded areas like CBDs or city centres. Thus, we can use the adaptive.density() to help overcome this.\n\nkde_origin_adaptive &lt;- adaptive.density(origin_sg_km, method=\"kernel\")\n\nkde_destination_adaptive &lt;- adaptive.density(destination_sg_km, method=\"kernel\")\n\nWe can see the KDE through these plots\n\nplot(kde_origin_adaptive)\n\n\n\n\n\nplot(kde_destination_adaptive)\n\n\n\n\n\n\n4.1.3 Converting KDE Output to Grid Object\nWe can convert the output into a grid object for a more suitable mapping without changing the result\n\ngrid_kde_origin &lt;- as.SpatialGridDataFrame.im(kde_origin_adaptive)\nspplot(grid_kde_origin)\n\n\n\n\n\ngrid_kde_destination &lt;- as.SpatialGridDataFrame.im(kde_destination_adaptive)\nspplot(grid_kde_destination)\n\n\n\n\n\n\n4.1.4 Converting Grid to Raster\nNext, we will conver the grid to a RasterLayer object using the raster() function\n\nkde_origin_raster &lt;- raster(kde_origin_adaptive)\nkde_origin_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.254928e-14, 2296.831  (min, max)\n\nkde_destination_raster &lt;- raster(kde_destination_adaptive)\nkde_destination_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.882384e-13, 1996.507  (min, max)\n\n\nSince there is no crs property when we first make a RasterLayer object, we can assign it\n\nprojection(kde_origin_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_origin_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.254928e-14, 2296.831  (min, max)\n\nprojection(kde_destination_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_destination_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.882384e-13, 1996.507  (min, max)\n\n\n\n\n4.1.5 Visualization\n\ntm_shape(kde_origin_raster) + \n  tm_raster(\"layer\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\ntm_shape(kde_destination_raster) + \n  tm_raster(\"layer\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n4.1.6 Testing Spatial Point Patterns Using Clark and Evans Test\n\nOrigin\nThe test hypotheses are:\nHo = The distribution of grab origin points are randomly distributed.\nH1= The distribution of grab origin points are not randomly distributed.\nThe 95% confident interval will be used.\nWe can use the CLark-Evans test of aggregation using clarkevans.test() from statspat\n\norigin_clarkevans &lt;- clarkevans.test(origin_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\norigin_clarkevans\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origin_ppp\nR = 0.21648, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe Clark-Evans test shows an R value that is much smaller than 1. This means that the points are very close to each other, implying that the points are clustered. The p-value also shows that we can reject the null hyphotesis that the distribution of grab origin points are randomly distributed\n\n\nDestination\nThe test hypotheses are:\nHo = The distribution of grab destination points are randomly distributed.\nH1= The distribution of grab destination points are not randomly distributed.\nThe 95% confident interval will be used.\n\ndestination_clarkevans &lt;- clarkevans.test(destination_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\ndestination_clarkevans\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  destination_ppp\nR = 0.23392, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe Clark-Evans test shows an R value that is much smaller than 1. This means that the points are very close to each other, implying that the points are clustered. The p-value also shows that we can reject the null hyphotesis that the distribution of grab destination points are randomly distributed"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#network-constrained-spatial-point-pattern-analysis",
    "href": "Take-home_Ex01/Take-home_Ex01.html#network-constrained-spatial-point-pattern-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.2 Network Constrained Spatial Point Pattern Analysis",
    "text": "4.2 Network Constrained Spatial Point Pattern Analysis\nFor Network Constrained Spatial Point Pattern Analysis, we are taking into account the roads in Singapore.\n\n4.2.1 Preparing Road Objects\nFirst, we prepare an object that contains roads in Singapore. We can use st_within to extract the roads from our dataset from OSM that matches/intersects with the MPSZ. Since we are only looking at roads that is suitable for cars, one way we can do it is by excluding rows where the max speed is 0\n\nsg_road &lt;- road_sf[st_contains(sg_sf, road_sf, sparse = FALSE), ] |&gt; filter(maxspeed &gt; 0)\nqtm(sg_road)\n\n\n\n\n\n\n4.2.2 NKDE for Origin\nFirst, let’s see how it looks like\n\ntm_shape(sg_road) + tm_lines() +\n  tm_shape(origin) + tm_dots('red', size=0.02)\n\n\n\n\n\n4.2.2.1 Preparing Origin Lixels and Line Centre Points\nWe will also extract the origin to include only those who are inside the Singapore main island’s boundary\n\norigin_events &lt;- origin[st_contains(sg_sf, origin, sparse = FALSE), ]\norigin_events &lt;- data.frame(origin_events$trj_id, origin_events$geometry) |&gt; st_as_sf(crs=3414)\nst_crs(origin_events)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nBefore performing NKDE, we need to cut the sg_road into lixels. In this example, our lixels will have a length of 700 and minimum length of 350\n\norigin_lixels &lt;- lixelize_lines(sg_road, \n                         700, \n                         mindist = 350)\n\n\norigin_samples &lt;- lines_center(origin_lixels)\n\n\n\n4.2.2.2 Performing NKDE\nWe will be using nkde.mc(), instead of the usual nkde(). The difference between the two functions is that when paired with the future package, nkde.mc allows for multiple workers to compute the nkde at the same time. We will also set the agg value to 20, which means that points within 20 metres of each other will be aggregrated. The grid_shape will also be set to c(16, 16) to indicate that we are splitting the data to a 16x16 grid that will be computated separately and combined together in the end. All these steps will help in making the runtime of the code a bit faster compared to using the usual default setup.\n\nfuture::plan(future::multisession(workers=4))\n\n\norigin_densities &lt;- nkde.mc(sg_road, \n                      events = origin_events,\n                      w = rep(1,nrow(origin_events)),\n                      samples = origin_samples,\n                      kernel_name = \"quartic\",\n                      bw = 300,\n                      adaptive = TRUE, # we use here an adaptive bandwidth\n                      trim_bw = 600, # the maximum local values of bandwidth will be 600m\n                      div= \"bw\",\n                      method = \"simple\", \n                      digits = 1, \n                      tol = 1,\n                      grid_shape = c(16,16), \n                      max_depth = 8,\n                      agg = 20,\n                      sparse = TRUE,\n                      verbose = FALSE)\n\nif (!inherits(future::plan(), \"sequential\")) future::plan(future::sequential)\n\n\n\n4.2.2.3 Insert Densities to Lixel and Sample\nAfter finishing the computation, we need to put the density value into the samples and lixels. Don’t forget to adjust the scale to kilometer\n\norigin_samples$density &lt;- origin_densities$k\norigin_lixels$density &lt;- origin_densities$k\n\norigin_samples$density &lt;- origin_samples$density*1000\norigin_lixels$density &lt;- origin_lixels$density*1000\n\n\n\n4.2.2.4 Visualization\nWe can use tmaps to visualize the result of our NKDE\n\ntm_shape(origin_lixels)+\n  tm_lines()+\ntm_shape(origin_samples)+\n  tm_dots(\"density\", style=\"kmeans\", palette=\"GnBu\", n=7, size=0.2)\n\n\n\n\n4.2.3 NKDE for Destination\nFor destination, we are doing the exact same process, but changing the event points to the destination points. To get the NKDE for Destination points, simply use the code for the Origin points, but change the dataset to the Destination dataset."
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#defining-a-kernel-density-map-function",
    "href": "Take-home_Ex01/Take-home_Ex01.html#defining-a-kernel-density-map-function",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "5.1 Defining a Kernel Density Map Function",
    "text": "5.1 Defining a Kernel Density Map Function\nFirst, we can create a function called density_map, which can be called later on to visualize our maps.\n\ndensity_map &lt;- function(raster_object, map_title) {\n  tm_basemap(\"OpenStreetMap\") +\ntm_shape(raster_object) +\n  tm_raster(\"layer\", alpha=0.65) + \n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            legend.height = 0.5, \n            legend.width = 0.4,\n            main.title = map_title,\n            main.title.position = 'center',\n            main.title.size = 1,\n            frame = FALSE)\n  }"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#plotting-density-map",
    "href": "Take-home_Ex01/Take-home_Ex01.html#plotting-density-map",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "5.2 Plotting Density Map",
    "text": "5.2 Plotting Density Map\nTo plot our density map, we can coll on the density_map function we defined before\n\norigin_density_map &lt;- density_map(kde_origin_raster, \"GrabPosisi Origin\")\norigin_density_map\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\ndestination_density_map &lt;- density_map(kde_destination_raster, \"GrabPosisi Destination\")\ndestination_density_map\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#saving-data-to-rds",
    "href": "Take-home_Ex01/Take-home_Ex01.html#saving-data-to-rds",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Saving data to RDS",
    "text": "Saving data to RDS\nWe can use write_rds() to save our loaded data into an RDS file, making it easier to reload any data we might need again\n\nwrite_rds(origin, 'data/rds/origin.rds')\nwrite_rds(destination, 'data/rds/destination.rds')\nwrite_rds(road_sf, 'data/rds/road_sf.rds')\nwrite_rds(mpsz2019_sf, 'data/rds/mpsz2019_sf.rds')\nwrite_rds(origin_lixels, 'data/rds/origin_lixels.rds')\nwrite_rds(destination_lixels, 'data/rds/destination_lixels.rds')\nwrite_rds(origin_samples, 'data/rds/origin_samples.rds')\nwrite_rds(destination_samples, 'data/rds/destination_samples.rds')\nwrite_rds(sg_road, 'data/rds/sg_road.rds')\nwrite_rds(origin_densities, 'data/rds/origin_densities.rds')\nwrite_rds(destination_densities, 'data/rds/destination_densities.rds')"
  },
  {
    "objectID": "Take-home_Ex01/Take-home_Ex01.html#loading-data-from-rds",
    "href": "Take-home_Ex01/Take-home_Ex01.html#loading-data-from-rds",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Loading data from RDS",
    "text": "Loading data from RDS\nWe can use read_rds() to reload any saved RDS file\n\norigin &lt;- read_rds('data/rds/origin.rds')\ndestination &lt;- read_rds('data/rds/destination.rds')\nroad_sf &lt;- read_rds('data/rds/road_sf.rds')\nmpsz2019_sf &lt;- read_rds('data/rds/mpsz2019_sf.rds')\nsg_sf &lt;- read_rds('data/rds/sg_sf.rds')\norigin_densities &lt;- read_rds('data/rds/origin_densities.rds')\ndestination_densities &lt;- read_rds('data/rds/destination_densities.rds')\norigin_lixels &lt;- read_rds('data/rds/origin_lixels.rds')\ndestination_lixels &lt;- read_rds('data/rds/destination_lixels.rds')\norigin_samples &lt;- read_rds('data/rds/origin_samples.rds')\ndestination_samples &lt;- read_rds('data/rds/destination_samples.rds')"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "we will learn how to compute Global and Local Measures of Spatial Autocorrelation (GMSA) by using spdep package."
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#packages",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#packages",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Packages",
    "text": "Packages\nUse this chunk to load the required packages\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#data",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#data",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Data",
    "text": "Data\nWe are using these data: - Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format. - Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\nLoading Data\nWe will use st_read() for the geospatial data, and read_csv() for the aspatial data\n\nhunan &lt;- st_read(dsn=\"data/geospatial\", layer='Hunan')\n\nReading layer `Hunan' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\nJoining data\nWe will use left_join() to combine the two data\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\nVisualization\nWe will use qtm() to prepare a basemap and a cloropeth map showing distribution of GDPPC 2012\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nWe need to construct a spatial weights of the study area first. We can use poly2nb() to do that. The code chunk below computes Queen contiguity weight matrix\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weight-matrix",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Row-standardised Weight Matrix",
    "text": "Row-standardised Weight Matrix\nNext, we can assign wights to the neighbouring polygon. This study will use equal weight (style=‘W’)\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#morans-test",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#morans-test",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran’s Test",
    "text": "Moran’s Test\nWe will learn how to use moran.test() from spdep\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nMonte Carlo Moran’s\nmoran.mc() can perform monte carlo simulation of the Moran’s test\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualization\nTo understand more about the test result, we can first get some statistical measures with summary()\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nThen, we can also plot a histogram with hist()\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#gearys-c",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#gearys-c",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Geary’s C",
    "text": "Geary’s C\nWe are also learning geary.test() from spdep\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nMonte Carlo Geary’s Test\ngeary.mc() can perform monte carlo simulation of the Moran’s test\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualization\nTo understand more about the test result, we can first get some statistical measures with summary()\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nThen, we can also plot a histogram with hist()\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Geary C\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#spatial-correlogram",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#spatial-correlogram",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlogram is used to examine patterns, showing how correlated are paris of spatial observations when we increase the distance\n\nMoran’s I correlogram\nWe can use sp.correlogram with method=“I”\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\nGeary’s C correlogram\nWe can use sp.correlogram with method=“I”\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#local-morans-i",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#local-morans-i",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Local Moran’s I",
    "text": "Local Moran’s I\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nMapping local Moran’s I values\nBefore mapping, it is wse to append the local Moran’s I dataframe to hunan SpatialolygonDataFrame\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nNow we can plot the local values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping local Moran’s p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran Scatterplot",
    "text": "Moran Scatterplot\nWe can use moran.plot()\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot-with-standardised-variable",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran scatterplot with standardised variable",
    "text": "Moran scatterplot with standardised variable\nFirst we can use scale() to scale the variables\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow we can plot it with this method\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#preparing-lisa-map-classes",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Preparing LISA map classes",
    "text": "Preparing LISA map classes\nFirst, we set a quadrant object.Next, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#lisa-map",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#lisa-map",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "LISA map",
    "text": "LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Getis and Ord’s G-Statistics",
    "text": "Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#distance-based-weight-matrix",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#distance-based-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Distance-Based Weight Matrix",
    "text": "Distance-Based Weight Matrix\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#determining-cut-off-distance",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#determining-cut-off-distance",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Determining Cut Off Distance",
    "text": "Determining Cut Off Distance\nStep-by-step: 1. Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep. 2. Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb(). 3. Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise. 4. Remove the list structure of the returned object by using unlist().\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#computing-fixed-distance-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Fixed Distance Weight Matrix",
    "text": "Computing Fixed Distance Weight Matrix\nWe can use dnearneigh() to get the weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAnd convert it into spatial weights object with nb2listw()\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Adaptive Distance Weight Matrix",
    "text": "Computing Adaptive Distance Weight Matrix\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nAnd convert it into spatial weights object with nb2listw()\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#fixed-distance",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#fixed-distance",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Fixed Distance",
    "text": "Fixed Distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\n\nCombine it to hunan sf data frame\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\nMapping Gi Values\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex05/Hands-on_Ex05.html#adaptive-distance",
    "href": "Hands-on_Ex05/Hands-on_Ex05.html#adaptive-distance",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Adaptive Distance",
    "text": "Adaptive Distance\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\nCombine it to hunan sf data frame\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\nMapping Gi Values\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Take-home_Ex01/data/Geospatial/MPSZ-2019/MPSZ-2019.html",
    "href": "Take-home_Ex01/data/Geospatial/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  }
]