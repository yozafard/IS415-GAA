[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m Yozafard Harold Siauheming, or Yoza for short, a Year 3 Information Systems student with a track in Business Analytics and second major in Data Science and Analytics"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "",
    "text": "I’m Yozafard Harold Siauheming, or Yoza for short, a Year 3 Information Systems student with a track in Business Analytics and second major in Data Science and Analytics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html",
    "title": "Hands On Exercise 1: Geospatial Data Science with R",
    "section": "",
    "text": "In this course, we are learning about Geospatial Analytics and Applications. Geospatial Data Science is the process of importing, wrangling, integrating, and processing geographic datasets.\nIn this exercise, we are looking into some geospatial data science tasks using R, specifically the sf packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#overview",
    "title": "Hands On Exercise 1: Geospatial Data Science with R",
    "section": "",
    "text": "In this course, we are learning about Geospatial Analytics and Applications. Geospatial Data Science is the process of importing, wrangling, integrating, and processing geographic datasets.\nIn this exercise, we are looking into some geospatial data science tasks using R, specifically the sf packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#dataset",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#dataset",
    "title": "Hands On Exercise 1: Geospatial Data Science with R",
    "section": "Dataset",
    "text": "Dataset\nWe will be using 4 publicly available datasets: - Master Plan 2014 Subzone Boundary (Web) from data.gov.sg - Pre-Schools Location from data.gov.sg - Cycling Path from LTADataMall - Latest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#setup",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#setup",
    "title": "Hands On Exercise 1: Geospatial Data Science with R",
    "section": "Setup",
    "text": "Setup\n\nPackage Import\nWe will be using sf to process geospatial data, along with tidyverse for data wrangling\n\n#Importing Packages\npacman::p_load(sf, tidyverse)\n\n\n\nData Loading\nWe can load data using the st_read() function\n\n#Loading data\nmpsz = st_read(dsn = \"./data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath = st_read(dsn = \"./data/geospatial\", \n                  layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nEDA\nIt is good practice to explore the dataset to understand more about its characteristic before performing deep analysis\n\n#Exploring mpsz data\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n#Plotting mpsz data\nplot(mpsz)\n\n\n\nplot(st_geometry(mpsz))\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#projecting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#projecting-geospatial-data",
    "title": "Hands On Exercise 1: Geospatial Data Science with R",
    "section": "Projecting Geospatial Data",
    "text": "Projecting Geospatial Data\nTo perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. That’s where projection comes into play\n\n#Projecing mpsz data\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n#Transforming preschool data to syv21\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\n\n#Importing and converting aspatial data\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\nlist(listings)\n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\n#Creating simple feature data frame\nlistings_sf &lt;- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs=4326) |&gt; st_transform(crs = 3414)\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/hands_on_1.html#geoprocessing-with-sf-package",
    "title": "Hands On Exercise 1: Geospatial Data Science with R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\n\nBuffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\n#Buffering\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist=5, nQuadSegs = 30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\nPoint-in-polygon Count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\n#Counting points in polygon\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\n#Density of pre-school by planning subzone\n\n#Derive each area of each planning subzone\nmpsz3414$Area &lt;- mpsz3414 |&gt; st_area()\n\n#Compute density with mutate\nmpsz3414 &lt;- mpsz3414 %&gt;% mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n#Plotting mpsz3414\nggplot(data=mpsz3414, aes(x= as.numeric(`PreSch Density`)))+ geom_histogram(bins=20, color=\"black\", fill=\"light blue\") + labs(title = \"Are pre-school even distributed in Singapore?\", subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\", x = \"Pre-school density (per km sq)\", y = \"Frequency\")\n\n\n\nggplot(data=mpsz3414, aes(y = `PreSch Count`, x= as.numeric(`PreSch Density`)))+ geom_point(color=\"black\", fill=\"light blue\") + xlim(0, 40) + ylim(0, 40) + labs(title = \"\", x = \"Pre-school density (per km sq)\", y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Let’s start with learning what a choropleth map is. A choropleth map is a thematic map that uses shades or patterns to visualize measurement of variables. For example, a choropleth map can be used to visualize population density or crime rate in a certain area.\nIn this exercise, we are looking into plotting maps choropleth maps using the tmap package in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#overview",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Let’s start with learning what a choropleth map is. A choropleth map is a thematic map that uses shades or patterns to visualize measurement of variables. For example, a choropleth map can be used to visualize population density or crime rate in a certain area.\nIn this exercise, we are looking into plotting maps choropleth maps using the tmap package in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#package-setup",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#package-setup",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "Package Setup",
    "text": "Package Setup\nThis exercise will primarily use the tmap package to create choropleths. Additionally, the sf package will be used to handle geospatial data, and tidyverse (specifically readr, tidyr, and dplyr) will also be used for processing data.\nThis code chunk will install and load the packages\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#data-sets",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "Data Sets",
    "text": "Data Sets\nTwo datasets will be used to create the choropleth map\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#data-import",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#data-import",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "Data Import",
    "text": "Data Import\nThis code chunk will use st_read() function to import MP14_SUBZONE_WEB_PL into R\n\nmpsz &lt;- st_read(dsn = \"./data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nUse this code chunk to examine the content of mpsz\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popdata.\nWe will use the read_csv() function to perform the task\n\npopdata &lt;- read_csv(\"./data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#data-preparation",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nBefore preparing a thematic map, we need to prepare a data table with values from year 2020. Here is the required variables:\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\nWe can use this code chunk to get the values\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\nThen, we need to join the attribute data with the geospatial data. But before we can do that, we need to convert to values in PA and SZ fields to uppercase so that it matches the SUBZONE_N and PLN_AREA_N\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nAfter we run the code chunk above, we can use the left_join function to join the tables together, where SUBZONE_N and SZ are the common identifier\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThen, save the mpsz_pop2020 to a .rds file\n\nwrite_rds(mpsz_pop2020, \"./data/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#choropleth-mapping-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/hands_on_2.html#choropleth-mapping-using-tmap",
    "title": "Hands On Exercise 2: Thematic Mapping and GeoVisualisation with R",
    "section": "Choropleth Mapping Using tmap",
    "text": "Choropleth Mapping Using tmap\nAs mentioned before, Choropleth mapping uses shades of colors or patterns in visualizing geospatial data.\nTwo approaches in preparing thematic map in tmap: 1. Using qtm(): quick and simple 2. Using tmap elements: customizable\n\nUsing qtm()\nFor simple thematic maps, qtm() provides a concise solution. the fill argument is where we put which attribute we want to map\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nUsing tmap_mode(‘plot’), we can generate a static map, while tmap_mode(‘view’) gives us an interactive mode\n\ntmap_mode(\"view\")\ntmap_options(check.and.fix = TRUE)\nqtm(mpsz_pop2020, \n    fill = \"AGED\")\n\n\n\n\n\n\n\n\nUsing tmap elements\nWhile qtm() is useful and concise, sometimes we might need something more customizable, and that is where tmap elements can come into play. Here is an example of a thematic map generated with tmap elements\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\nNow we will break down the functions used to plot these elements\n\nBase map\ntm_shape() is the basic building block, followed by one more layer elements such as tm_fill() and tm_polygons()\n\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n\nDrawing the map with tm_polygons\nWe can use tm_polygons(variable), where variable refers to the target variable we want to assign\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n####Drawing the map with tm_fill() and tm_border() tm_polygons() is a wrapper of tm_fill() and tm_border(), where tm_fill shades the polygons, while tm_border() gives the borders.\n\n#tm_fill alone\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n#tm_border alone\ntm_shape(mpsz_pop2020)+\n  tm_borders(lwd=0.1, alpha=1)\n\n\n\n\n\n\n#Combined\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\nData classification in tmap\nMost choropleth maps uses some type of data classification, to group large number of observations to certain ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks. To define which method to use, the style argument from the tm_polygons() or tm_fill() layer is used.\n\nBuilt-in methods\n\n#Jenks\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n#Equal\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 3,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDifferent methods have different ways of separating the classes, so choose a method that suits our needs. We also need to find the right number of classes. Too many classes might look too cluttered, while too little classes might not give us enough information to draw any meaningful insights\n\n\nCustome break\nWhen we need to set the breakpoints by ourselves (instead of using the built-in functions), we can set it explicitly in the breaks argument of tm_fill() (note that to get n classes, input n+1 elements in the breaks argument, in increasing order)\n\n#Good practice to perform EDA before specifying breakpoints\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nFrom the summary above, it gives us a good gauge on how to set our breakpoints.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nSetting Colour Scheme\nWe can define our won colour ramps, or use RColorBrewer package\n\nColourBrewer\nWe can assign our colour ramps in the palette argument of tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nWe can add “-” before the colour to reverse it\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nLayouts Map\nlayout is the combination of all map elements\n\nMap Legend\ntmap provides several legend options\n\ntmap_mode('plot')\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n#Map Style\ntmap also have preset styles, called using tmap_style()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\nCartographic Furniture\ntmap also has other map furnitures that can be useful, such as compass, scale bar, and grid lines\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nWe can reset to default style with this chunk below\n\ntmap_style(\"white\")\n\n\n\n\nSmall Multiple Choropleth Maps\nSmall multiple maps, or facet maps, are just as the name suggests: multiple small maps arranged side-by-side or stacked vertically. This is useful in visualizing how the relationship changes with respect to another variable.\nIn tmap, there are 3 ways to plot facet maps - by assigning multiple values to at least one - of the asthetic arguments, - by defining a group-by variable in tm_facets(), and - by creating multiple stand-alone maps with tmap_arrange().\n\nAssigining multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nUsing tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nUsing tmap_arrange() to create multiple stand-alone maps\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\nMapping Spatial Object That Meets a Criteria\nWe can also use a selection function to map only objects that meet s the selection criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Let’s start with learning what spatial point analysis is. Spatial point analysis is the evaluation of a pattern or distribution of a set points referring to location on a surface. These points can be the location of: - An event (crime, accident, disease, etc) - A business service (coffee shop, supermarket, etc)\nIn this lesson, we will be using the spatstat library to answer these questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#overview",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Let’s start with learning what spatial point analysis is. Spatial point analysis is the evaluation of a pattern or distribution of a set points referring to location on a surface. These points can be the location of: - An event (crime, accident, disease, etc) - A business service (coffee shop, supermarket, etc)\nIn this lesson, we will be using the spatstat library to answer these questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#datasets",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Datasets",
    "text": "Datasets\nThere are 3 datasets to be used - CHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from data.gov.sg and is in geojson format. - MP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg. - CostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#packages-setup",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#packages-setup",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Packages Setup",
    "text": "Packages Setup\nWe are using 5 packages: - sf for processing geospatial data in R - spatstat for point pattern analysis - raster for processing gridded spatial data. We will use raster to convert the image output from spatsat to a raster format - maptools for manipulating geospatial data. We mainly use it to conver spatial data into ppp format of spatstat - tmap to plot point pattern maps"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#spatial-data-wrangling",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Spatial Data Wrangling",
    "text": "Spatial Data Wrangling\n\nImporting Data\nWe are using st_read() and st_transform() to load 3 data sets to R\n\n\nReading layer `ChildCareServices' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nRetrieve the referencing system information of these geospatial data\nWe can use st_crs() to retrieve the referencing system information\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe can see that childcare_sf is in WGS84, while mpsz_sf and sg_sf is in SVY21. To address this, we can use the st_transform()\nNow let’s check their new referencing system information\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nMapping The Data\nTo see their spatial patterns, we can explore plotting the data using tmap functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#geospatial-data-wrangling",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nWe have experienced the use of simple feature data frames. However, sometimes we need to use the data in a sp’s Spatial* classes\n\nConverting sf data frames to sp’s Spatial* class\nWe will be using as_Spatial() function from sf package\nTo display the information of these 3 spatial classes:\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1925 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;100044&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;44, TELOK BLANGAH DRIVE, #01 - 19/51, SINGAPORE 100044&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;PCF SPARKLETOTS PRESCHOOL @ TELOK BLANGAH BLK 44 (CC)&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;349C54F201805938&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093837&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                                            &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;99982&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;35, ALLANBROOKE ROAD, SINGAPORE 099982&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;ISLANDER PRE-SCHOOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;4F63ACF93EFABE7F&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093837&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\nConverting Spatial* class to generic sp format\nspatstat requires the data to be in ppp object form. However, there is no direct way to convert Spatial* class to ppp object. So, we need to convert it to Spatial objects first\nTo show the object properties\n\n\nclass       : SpatialPoints \nfeatures    : 1925 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\nConverting Generic sp Format to spatstat’s ppp Format\n\n\nPlanar point pattern: 1925 points\nwindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n\n\nLet’s see what the difference is in a plot\n\n\n\n\n\nTo get the summary statistics, we can use this code\n\n\nPlanar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nHandling duplicated points\nWe can check if there are any duplicates with this\n\n\n[1] TRUE\n\n\nTo count the number of co-incidence points, we can use the multiplicity() function\n\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    2    1    1    1    1    2    1    1    1    1    1    1    3    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    4    1    1    1    1    1    1    1    1    1    1    2 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    2    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    3    1    1    1    2    1   10    1    1    1    1    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    2    1    1    3    1    1    1    2    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    2    2    2    1    1    1    1    1    1    1    1    2    1    1    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    3    1    1    1    1    1    1    1    1    1    1 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    2    2    2    1    1    1    1    1    2    1    4    1    1    2 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   3    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   1    1    1    1    1   10    1    1    3    1    1    1    1    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    2    6    1    2    1    1    2    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   3    2    3    2    1    2    1    1    2    4    1    6    6    1    1    1 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   2    1    1    1    1    2    1    1    1    1    1    1    3    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    4    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    2    1    1    1    2    1    1    1    2    1    1    1    1    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    2    1    2    2    1    1    1    1    2    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   4    1    1    1    1    2    1    1    1    1    1    1    2    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   2    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   2    2    1    1    1    1    1   10    1    2    1    1    1    2    1    3 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1   10   10   10    1    1    1    1    1    1    1    1    1 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    2    1    2    1    1    1    1    3    1    2    1    1    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    3    1    1    1    1    1    2    1    1    2 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    3    1    1    1    1    1    1    1    1    2    2    2    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    3    1    1    1    2    1    1    1    2    2    1    1    1    1    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    4    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   1    1    1    1    1    3    1    1    1    1    1    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    4    1    1    1    1    1    1    4    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    2    1    1 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    3    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    1    1    1    1   10    1    1    1    1    1    2 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    1    2    1    2    1   10    1    4    1    2    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   3    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    3    1    1    3    1    1    1    1    2    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    2 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    2    1    1    1    1    1    2    2    1    1    1    1    2    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    2    1    2    1    1    1    2    1    1    1    2    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    2    1    1    2    1    1    1    1    1    1    1    1    2    1 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    2    2    1    1    1    1    2    1    1    1    1    2    1    1    2 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    2    4    1    1    1    1    1    1    2    1    2    2    2 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   2    1    1    1    1    2    1    1    2    2    2    2    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   2    1    1    1    2    1    2    1    1    1    1    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    2    2    2    1    1    1    1    1    2    1    1    2    2    2    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    2    1    1    2    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   2    1    2    1    2    1    1    1    1    1    1    2    2    1    1    2 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    2    1    2    1    2    1    1    1    1    1    2    1    1    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    2    1    2    2    2    2    2    1    1    1    1    1    2    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    2    1    1    2    1    1    1    1    2    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    2    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    3    1    1    1    1    1    1    1   10 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   2    1    3    2    1    2    1    1    2    3    2    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    2    1    2    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    4    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   2    1    1    1    2    1    2    1    1    1    1    1    1    1    1    1 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n  10    1    2    4    1    1    1    4    1    4    1    1    1    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    1    1    1    1    1    4    2    3    2    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   2    2    1    1    1    1    1    2    2    3    1    1    1    1    1    2 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   2    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   2    2    2    1    1    1    6    1    1    1    1    1    1    1    1    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    1    1    4    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    2    2    1    1    1    1    1    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    2    1    1    1    1    2    1    1    1    1    2    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   2    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   2    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 \n   1    1    1    1    1    1    1    1    1    6    1    1    1    1    1    1 \n1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 \n   1    1    1    1    1    1    1    3    1    1    4    1    1    2    1    1 \n1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 \n   2    1    1    1    2    1    4    1    2    1    1    1    1    1    1    1 \n1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 \n   1    1    1    1    1    1    1    1    2    1    1    2    1    1    1    1 \n1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 \n   1    1    1    1    2    1    1    3    1    1    1    2    1    1    1    1 \n1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 \n   2    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 \n   3    1    1    2    1    1    1    1    1    1    1    1    1    2    1    1 \n1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 \n   1    1    1    4    1    1    1    6    1    1    1    1    1    1    1    1 \n1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 \n   1    1    1    2    1    1    1    2    1    1    1    1    1    2    1    1 \n1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 \n   1    2    1    1    1    1    1    1    1    1    2    2    2    1    1    1 \n1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 \n   2    1    2    1    2    1    2    1    1    2    1    2    2    2    2    1 \n1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 \n   1    1    1    1    1    2    1    1    1    2    1    1    1    1    2    1 \n1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 \n   1    4    1    4    1    4    1    1    2    1    1    1    1    1    3    1 \n1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 \n   1    1    1    2    2    2    2    2    2    2    2    1    1    2    2    2 \n1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 \n   1    2    1    1    1    1    1    2    2    2    1    2    2    2    2    1 \n1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 \n   2    1    1    1    1    1    1    1    2    2    1    2    1    1    1    1 \n1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 \n   1    1    1    1    2    1    2    2    2    2    2    2    1    1    2    1 \n1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 \n   1    1    1    2    2    2    2    2    1    1    1    2    1    1    2    2 \n1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 \n   1    2    1    1    2    1    1    2    2    2    1    2    1    2    1    1 \n1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 \n   1    1    1    1    1    1    2    1    1    1    1    4    1    1    1    1 \n1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 \n   3    1    1    2    1    1    1    2    1    1    1    1    1    2    2    1 \n1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 \n   1    1    2    1    2    2    1    1    1    1    1    2    1    1    2    1 \n1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 \n   1    3    2    2    2    1    2    1    3    1    1    1    1    1    1    1 \n1921 1922 1923 1924 1925 \n   1    1    1    1    3 \n\n\nTo see how many locations have more than one point event, sum up the multiplicity\n\n\n[1] 338\n\n\nNow, we can plot out where these duplicate point events are\n\n\n\n\n\n\n\nTo overcome duplicates, there are three main ways: 1. Delete the duplicates: loss of useful point events 2. Jittering: add a small perturbation to the duplicate points so that they do not occupy the exact same space 3. Make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks\nThis code chunk implements the jittering approach\nAfter implementing the jittering approach, let’s see if there are still any duplicates\n\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#owin-object",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "owin Object",
    "text": "owin Object\nAn owin object is specially designed to represent a certain polygonal region that we are analysing (e.g. Singapore). The code chunk below converts sg SpatialPolygon object into an owin object of spatstat\nLet’s see what it looks like by plotting it\n\n\n\n\n\n\nCombining point events object and owin object\n\n\nPlanar point pattern:  1925 points\nAverage intensity 2.570982e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\nNow, we can try to plot it out"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#first-order-spatial-point-pattern-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#first-order-spatial-point-pattern-analysis",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "First-Order Spatial Point Pattern Analysis",
    "text": "First-Order Spatial Point Pattern Analysis\nWe will be larning about first-order SPPA with spatsat, focusing on: - deriving kernel density estimation (KDE) layer - performing confirmatory spatial point patterns analysis with nearest neighbour statistics\n\nKernel Density Estimation\nWe will use the density() function, along with these configurations: - bw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl(). - The smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”. - The intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE\nafter getting the kde, we can plot it\n\n\n\n\n\nWe can also compute the bandwith with this code\n\n\n   sigma \n306.6986 \n\n\nWe can also rescale the unit of measurement (e.g. from meter to kilometer)\nNow we can re-run the density() with the rescaled data\n\n\n\n\n\nIt still looks similar to the one before, with the difference in the data values in the legend\n\n\nWorking with different automatic bandwidth methods\nBesides bw.diggle(), there are 3 other functions:\n\nbw.Cvl()\n\n\n\n   sigma \n4.543278 \n\n\n\nbw.scott()\n\n\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\nbw.ppl()\n\n\n\n    sigma \n0.3897114 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() when the pattern consists predominantly of tight clusters. But if the purpose is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nHere is a comparison of both algorithms\n\n\n\n\n\n\n\nWorking with different kernel methods\nBy default, density() uses the gaussian method, but we can use other methods also."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#fixed-and-adaptive-kde",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Fixed and Adaptive KDE",
    "text": "Fixed and Adaptive KDE\n\nKDE Using Fixed Bandwidth\nwe will try computing a KDE layer with a bandwidth of 600 meters. Since the unit of measurement is in km, 600 meters = 0.6 km\n\n\n\n\n\n\n\nKDE Using Adaptive Bandwidth\nFixed bandwidth is very sensitive to skewness in distribution. One solution is to use adaptive bandwidth with the adaptive.density() function\n\n\n\n\n\nHere is a comparison of fixed and adaptive kde\n\n\n\n\n\n\n\nConverting KDE output into grid object\n\n\n\n\n\n\n\nConverting Gridded Output to Raster\nWe can use the raster() function to do so\nLet’s take a look at the properties\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.014191e-14, 32.45281  (min, max)\n\n\nNotice that the crs property is NA. We can include the CRS information on the layer\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -1.014191e-14, 32.45281  (min, max)\n\n\n\n\ntmap Visualisation\n\n\n\n\n\n\n\nComparing Spatial Point Patterns using KDE\nWe are comparing KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas\nFirst, we extract the target planning areas\nPlotting the target planning areas\n\n\n\n\n\nThen, we convert it into generic sp format\nThen, create the owin object\nAnd extract the childcare within the region\nRescale it to kilometre\nPlot the location of the childcare centres\n\n\n\n\n\nNow, we can compute the KDE. We are using bw.diggle for the bandwidth\n\n\n\n\n\nCompare it with a fixed bandwidth of 250m"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_1.html#nearest-neighbour-analysis",
    "title": "Hands On Exercise 3.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Nearest Neighbour Analysis",
    "text": "Nearest Neighbour Analysis\nWe will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test()\nHypotheses: Ho = The distribution of childcare services are randomly distributed. H1= The distribution of childcare services are not randomly distributed. Confidence interval = 95%\n\nTesting Spatial Point Patterns\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.5062, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nthe R value suggests that there is a tendency towrds clustering in the distribution of childcare services. The p-value indicates that the observed clustering is statistically significant. Thus, we can say that the distribution of childcare services is not random\n\n\nClark-Evans Test: Choa Chu Kang\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.87086, p-value = 0.03357\nalternative hypothesis: two-sided\n\n\n\n\nClark-Evans Test: Tampines\n\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.69482, p-value = 2.701e-10\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Let’s start with learning what spatial point analysis is. Spatial point analysis is the evaluation of a pattern or distribution of a set points referring to location on a surface. These points can be the location of: - An event (crime, accident, disease, etc) - A business service (coffee shop, supermarket, etc)\nIn this lesson, we will be using the spatstat library to answer these questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#overview",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Let’s start with learning what spatial point analysis is. Spatial point analysis is the evaluation of a pattern or distribution of a set points referring to location on a surface. These points can be the location of: - An event (crime, accident, disease, etc) - A business service (coffee shop, supermarket, etc)\nIn this lesson, we will be using the spatstat library to answer these questions:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#datasets",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Datasets",
    "text": "Datasets\nThere are 3 datasets to be used - CHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from data.gov.sg and is in geojson format. - MP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from data.gov.sg. - CostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#packages-setup",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#packages-setup",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Packages Setup",
    "text": "Packages Setup\nWe are using 5 packages: - sf for processing geospatial data in R - spatstat for point pattern analysis - raster for processing gridded spatial data. We will use raster to convert the image output from spatsat to a raster format - maptools for manipulating geospatial data. We mainly use it to conver spatial data into ppp format of spatstat - tmap to plot point pattern maps\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#spatial-data-wrangling",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Spatial Data Wrangling",
    "text": "Spatial Data Wrangling\n\nImporting Data\nWe are using st_read() and st_transform() to load 3 data sets to R\n\n#Childcare Data\nchildcare_sf &lt;- st_read(\"../Hands-on_Ex03/data/ChildCareServices.geojson\") |&gt; st_transform(crs=3414)\n\nReading layer `ChildCareServices' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n#Coastal Outline\nsg_sf &lt;- st_read('../Hands-on_Ex03/data', layer='CostalOutline')\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\n#MPSZ\nmpsz_sf &lt;- st_read('../Hands-on_Ex03/data', layer='MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nRetrieve the referencing system information of these geospatial data\nWe can use st_crs() to retrieve the referencing system information\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe can see that childcare_sf is in WGS84, while mpsz_sf and sg_sf is in SVY21. To address this, we can use the st_transform()\n\nmpsz_sf &lt;- st_transform(mpsz_sf, crs= 3414)\nsg_sf &lt;- st_transform(sg_sf, crs= 3414)\n\nNow let’s check their new referencing system information\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nMapping The Data\nTo see their spatial patterns, we can explore plotting the data using tmap functions\n\ntmap_options(check.and.fix = TRUE)\ntm_shape(sg_sf) + tm_polygons() +\n  tm_shape(mpsz_sf) + tm_polygons() + \n    tm_shape(childcare_sf) + tm_dots()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#geospatial-data-wrangling",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\nWe have experienced the use of simple feature data frames. However, sometimes we need to use the data in a sp’s Spatial* classes\n\nConverting sf data frames to sp’s Spatial* class\nWe will be using as_Spatial() function from sf package\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nTo display the information of these 3 spatial classes:\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1925 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;100044&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;44, TELOK BLANGAH DRIVE, #01 - 19/51, SINGAPORE 100044&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;PCF SPARKLETOTS PRESCHOOL @ TELOK BLANGAH BLK 44 (CC)&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;349C54F201805938&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093837&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                                            &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;99982&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;35, ALLANBROOKE ROAD, SINGAPORE 099982&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;ISLANDER PRE-SCHOOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;4F63ACF93EFABE7F&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093837&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\nConverting Spatial* class to generic sp format\nspatstat requires the data to be in ppp object form. However, there is no direct way to convert Spatial* class to ppp object. So, we need to convert it to Spatial objects first\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nTo show the object properties\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1925 \nextent      : 11810.03, 45404.24, 25596.33, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\nConverting Generic sp Format to spatstat’s ppp Format\n\nchildcare_ppp &lt;- as(childcare_sp, 'ppp')\nchildcare_ppp\n\nPlanar point pattern: 1925 points\nwindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n\n\nLet’s see what the difference is in a plot\n\nplot(childcare_ppp)\n\n\n\n\nTo get the summary statistics, we can use this code\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nHandling duplicated points\nWe can check if there are any duplicates with this\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-incidence points, we can use the multiplicity() function\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    2    1    1    1    1    2    1    1    1    1    1    1    3    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    4    1    1    1    1    1    1    1    1    1    1    2 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    2    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    3    1    1    1    2    1   10    1    1    1    1    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    2    1    1    3    1    1    1    2    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    2    2    2    1    1    1    1    1    1    1    1    2    1    1    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    3    1    1    1    1    1    1    1    1    1    1 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    2    2    2    1    1    1    1    1    2    1    4    1    1    2 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   3    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   1    1    1    1    1   10    1    1    3    1    1    1    1    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    2    6    1    2    1    1    2    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   3    2    3    2    1    2    1    1    2    4    1    6    6    1    1    1 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   2    1    1    1    1    2    1    1    1    1    1    1    3    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    4    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    2    1    1    1    2    1    1    1    2    1    1    1    1    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    2    1    2    2    1    1    1    1    2    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   4    1    1    1    1    2    1    1    1    1    1    1    2    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   2    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   2    2    1    1    1    1    1   10    1    2    1    1    1    2    1    3 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1   10   10   10    1    1    1    1    1    1    1    1    1 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    2    1    2    1    1    1    1    3    1    2    1    1    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    3    1    1    1    1    1    2    1    1    2 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    3    1    1    1    1    1    1    1    1    2    2    2    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    3    1    1    1    2    1    1    1    2    2    1    1    1    1    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    4    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   1    1    1    1    1    3    1    1    1    1    1    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    4    1    1    1    1    1    1    4    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    2    1    1 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    3    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    1    1    1    1   10    1    1    1    1    1    2 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    1    2    1    2    1   10    1    4    1    2    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   3    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    3    1    1    3    1    1    1    1    2    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    2 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    2    1    1    1    1    1    2    2    1    1    1    1    2    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    2    1    2    1    1    1    2    1    1    1    2    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    2    1    1    2    1    1    1    1    1    1    1    1    2    1 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    2    2    1    1    1    1    2    1    1    1    1    2    1    1    2 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    2    4    1    1    1    1    1    1    2    1    2    2    2 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   2    1    1    1    1    2    1    1    2    2    2    2    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   2    1    1    1    2    1    2    1    1    1    1    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    2    2    2    1    1    1    1    1    2    1    1    2    2    2    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    2    1    1    2    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   2    1    2    1    2    1    1    1    1    1    1    2    2    1    1    2 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    2    1    2    1    2    1    1    1    1    1    2    1    1    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    2    1    2    2    2    2    2    1    1    1    1    1    2    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    2    1    1    2    1    1    1    1    2    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    2    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    3    1    1    1    1    1    1    1   10 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   2    1    3    2    1    2    1    1    2    3    2    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    2    1    2    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    4    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   2    1    1    1    2    1    2    1    1    1    1    1    1    1    1    1 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n  10    1    2    4    1    1    1    4    1    4    1    1    1    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    1    1    1    1    1    4    2    3    2    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   2    2    1    1    1    1    1    2    2    3    1    1    1    1    1    2 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   2    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   2    2    2    1    1    1    6    1    1    1    1    1    1    1    1    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    1    1    4    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    2    2    1    1    1    1    1    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    2    1    1    1    1    2    1    1    1    1    2    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   2    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   2    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 \n   1    1    1    1    1    1    1    1    1    6    1    1    1    1    1    1 \n1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 \n   1    1    1    1    1    1    1    3    1    1    4    1    1    2    1    1 \n1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 \n   2    1    1    1    2    1    4    1    2    1    1    1    1    1    1    1 \n1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 \n   1    1    1    1    1    1    1    1    2    1    1    2    1    1    1    1 \n1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 \n   1    1    1    1    2    1    1    3    1    1    1    2    1    1    1    1 \n1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 \n   2    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 \n   3    1    1    2    1    1    1    1    1    1    1    1    1    2    1    1 \n1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 \n   1    1    1    4    1    1    1    6    1    1    1    1    1    1    1    1 \n1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 \n   1    1    1    2    1    1    1    2    1    1    1    1    1    2    1    1 \n1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 \n   1    2    1    1    1    1    1    1    1    1    2    2    2    1    1    1 \n1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 \n   2    1    2    1    2    1    2    1    1    2    1    2    2    2    2    1 \n1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 \n   1    1    1    1    1    2    1    1    1    2    1    1    1    1    2    1 \n1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 \n   1    4    1    4    1    4    1    1    2    1    1    1    1    1    3    1 \n1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 \n   1    1    1    2    2    2    2    2    2    2    2    1    1    2    2    2 \n1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 \n   1    2    1    1    1    1    1    2    2    2    1    2    2    2    2    1 \n1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 \n   2    1    1    1    1    1    1    1    2    2    1    2    1    1    1    1 \n1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 \n   1    1    1    1    2    1    2    2    2    2    2    2    1    1    2    1 \n1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 \n   1    1    1    2    2    2    2    2    1    1    1    2    1    1    2    2 \n1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 \n   1    2    1    1    2    1    1    2    2    2    1    2    1    2    1    1 \n1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 \n   1    1    1    1    1    1    2    1    1    1    1    4    1    1    1    1 \n1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 \n   3    1    1    2    1    1    1    2    1    1    1    1    1    2    2    1 \n1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 \n   1    1    2    1    2    2    1    1    1    1    1    2    1    1    2    1 \n1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 \n   1    3    2    2    2    1    2    1    3    1    1    1    1    1    1    1 \n1921 1922 1923 1924 1925 \n   1    1    1    1    3 \n\n\nTo see how many locations have more than one point event, sum up the multiplicity\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 338\n\n\nNow, we can plot out where these duplicate point events are\n\ntmap_mode('view')\ntm_shape(childcare) + tm_dots(alpha=0.4, size=0.05)\n\n\n\n\n\n\n\n#Change back the mode to 'plot' to save up on resources\ntmap_mode('plot')\n\nTo overcome duplicates, there are three main ways: 1. Delete the duplicates: loss of useful point events 2. Jittering: add a small perturbation to the duplicate points so that they do not occupy the exact same space 3. Make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks\nThis code chunk implements the jittering approach\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nAfter implementing the jittering approach, let’s see if there are still any duplicates\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#owin-object",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "owin Object",
    "text": "owin Object\nAn owin object is specially designed to represent a certain polygonal region that we are analysing (e.g. Singapore). The code chunk below converts sg SpatialPolygon object into an owin object of spatstat\n\nsg_owin &lt;- as(sg_sp, 'owin')\n\nLet’s see what it looks like by plotting it\n\nplot(sg_owin)\n\n\n\n\n\nCombining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1925 points\nAverage intensity 2.570982e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\nNow, we can try to plot it out\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#second-order-spatial-point-pattern-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/hands_on_3_2.html#second-order-spatial-point-pattern-analysis",
    "title": "Hands On Exercise 3.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Second-Order Spatial Point Pattern Analysis",
    "text": "Second-Order Spatial Point Pattern Analysis\nBefore going to the analysis, we need to extract the study area\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlot it to check\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\nConvert it into sp format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\nThen, create the owin object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\nAnd extract the childcare within the region\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nRescale it to kilometre\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nPlot the location of the childcare centres\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\nG-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. We will be learning how to compute G-function estimation using Gest() from the spatstat package, and perform monte carlo simulation using envelope() from spatstat.\n\nChoa Chu Kang Planning Area\nFirst, we use Gest() to compute the G-function\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\nTampines Planning Area\nFirst, we use Gest() to compute the G-function\n\nG_tm = Gest(childcare_tm_ppp, correction = \"border\")\nplot(G_tm, xlim=c(0,500))\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)\n\n\n\n\n\n\nF-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. We will be learning how to compute F-function estimation using Fest() from the spatstat package, and perform monte carlo simulation using envelope() from spatstat.\n\nChoa Chu Kang Planning Area\nFirst, we use Fest() to compute the F-function\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\n\n\nTampines Planning Area\nFirst, we use Fest() to compute the F-function\n\nF_tm = Fest(childcare_tm_ppp)\nplot(F_tm)\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_tm.csr)\n\n\n\n\n\n\n\nK-Function\nK-function measures the number of events found up to a given distance of any particular event. We will be learning how to compute K-function estimation using Kest() from the spatstat package, and perform monte carlo simulation using envelope() from spatstat.\n\nChoa Chu Kang Planning Area\nFirst, we use Kest() to compute the K-function\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nK_CK.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(K_CK.csr)\n\n\n\n\n\n\nTampines Planning Area\nFirst, we use Kest() to compute the K-function\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10 [3:46 remaining] .........20 [3:49 remaining] ...\n......30 [3:49 remaining] .........40 [3:46 remaining] .........50 [3:45 remaining] ..\n.......60 [3:43 remaining] .........70 [3:42 remaining] .........80 [3:39 remaining] .\n........90 [3:38 remaining] .........100 [3:39 remaining] .........110\n [3:37 remaining] .........120 [3:35 remaining] .........130 [3:32 remaining] .........\n140 [3:30 remaining] .........150 [3:27 remaining] .........160 [3:25 remaining] ........\n.170 [3:24 remaining] .........180 [3:21 remaining] .........190 [3:18 remaining] .......\n..200 [3:16 remaining] .........210 [3:14 remaining] .........220 [3:12 remaining] ......\n...230 [3:09 remaining] .........240 [3:07 remaining] .........250 [3:04 remaining] .....\n....260 [3:02 remaining] .........270 [2:59 remaining] .........280 [2:56 remaining] ....\n.....290 [2:53 remaining] .........300 [2:51 remaining] .........310 [2:48 remaining] ...\n......320 [2:46 remaining] .........330 [2:44 remaining] .........340 [2:41 remaining] ..\n.......350 [2:39 remaining] .........360 [2:36 remaining] .........370 [2:33 remaining] .\n........380 [2:31 remaining] .........390 [2:28 remaining] .........400\n [2:26 remaining] .........410 [2:23 remaining] .........420 [2:21 remaining] .........\n430 [2:18 remaining] .........440 [2:16 remaining] .........450 [2:13 remaining] ........\n.460 [2:11 remaining] .........470 [2:09 remaining] .........480 [2:06 remaining] .......\n..490 [2:04 remaining] .........500 [2:01 remaining] .........510 [1:59 remaining] ......\n...520 [1:56 remaining] .........530 [1:54 remaining] .........540 [1:51 remaining] .....\n....550 [1:49 remaining] .........560 [1:47 remaining] .........570 [1:44 remaining] ....\n.....580 [1:42 remaining] .........590 [1:40 remaining] .........600 [1:37 remaining] ...\n......610 [1:35 remaining] .........620 [1:32 remaining] .........630 [1:30 remaining] ..\n.......640 [1:27 remaining] .........650 [1:25 remaining] .........660 [1:22 remaining] .\n........670 [1:20 remaining] .........680 [1:17 remaining] .........690\n [1:15 remaining] .........700 [1:13 remaining] .........710 [1:10 remaining] .........\n720 [1:08 remaining] .........730 [1:05 remaining] .........740 [1:03 remaining] ........\n.750 [1:01 remaining] .........760 [58 sec remaining] .........770 [56 sec remaining] .......\n..780 [53 sec remaining] .........790 [51 sec remaining] .........800 [49 sec remaining] ......\n...810 [46 sec remaining] .........820 [44 sec remaining] .........830 [41 sec remaining] .....\n....840 [39 sec remaining] .........850 [36 sec remaining] .........860 [34 sec remaining] ....\n.....870 [31 sec remaining] .........880 [29 sec remaining] .........890 [27 sec remaining] ...\n......900 [24 sec remaining] .........910 [22 sec remaining] .........920 [19 sec remaining] ..\n.......930 [17 sec remaining] .........940 [14 sec remaining] .........950 [12 sec remaining] .\n........960 [9 sec remaining] .........970 [7 sec remaining] .........980\n [5 sec remaining] .........990 [2 sec remaining] ........\n999.\n\nDone.\n\nplot(K_tm.csr)\n\n\n\n\n\n\n\nL-Function\nWe will be learning how to compute K-function estimation using Lest() from the spatstat package, and perform monte carlo simulation using envelope() from spatstat.\n\nChoa Chu Kang Planning Area\nFirst, we use Lest() to compute the L-function\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nL_CK.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(K_CK.csr)\n\n\n\n\n\n\nTampines Planning Area\nFirst, we use Lest() to compute the K-function\n\nL_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\nTo confirm the spatial pattern that we observe above, we can do a hypothesis testing\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nalpha-value = 0.001\nNow we perform a monte carlo test\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10 [4:37 remaining] .........20 [4:28 remaining] ...\n......30 [4:19 remaining] .........40 [4:11 remaining] .........50 [4:10 remaining] ..\n.......60 [4:05 remaining] .........70 [4:00 remaining] .........80 [3:55 remaining] .\n........90 [3:49 remaining] .........100 [3:44 remaining] .........110\n [3:41 remaining] .........120 [3:37 remaining] .........130 [3:33 remaining] .........\n140 [3:32 remaining] .........150 [3:29 remaining] .........160 [3:27 remaining] ........\n.170 [3:24 remaining] .........180 [3:21 remaining] .........190 [3:19 remaining] .......\n..200 [3:16 remaining] .........210 [3:14 remaining] .........220 [3:11 remaining] ......\n...230 [3:08 remaining] .........240 [3:05 remaining] .........250 [3:02 remaining] .....\n....260 [2:59 remaining] .........270 [2:58 remaining] .........280 [2:55 remaining] ....\n.....290 [2:53 remaining] .........300 [2:51 remaining] .........310 [2:48 remaining] ...\n......320 [2:46 remaining] .........330 [2:43 remaining] .........340 [2:41 remaining] ..\n.......350 [2:38 remaining] .........360 [2:36 remaining] .........370 [2:33 remaining] .\n........380 [2:31 remaining] .........390 [2:28 remaining] .........400\n [2:26 remaining] .........410 [2:23 remaining] .........420 [2:21 remaining] .........\n430 [2:18 remaining] .........440 [2:15 remaining] .........450 [2:13 remaining] ........\n.460 [2:11 remaining] .........470 [2:08 remaining] .........480 [2:06 remaining] .......\n..490 [2:04 remaining] .........500 [2:01 remaining] .........510 [1:59 remaining] ......\n...520 [1:56 remaining] .........530 [1:54 remaining] .........540 [1:51 remaining] .....\n....550 [1:49 remaining] .........560 [1:46 remaining] .........570 [1:44 remaining] ....\n.....580 [1:42 remaining] .........590 [1:39 remaining] .........600 [1:37 remaining] ...\n......610 [1:34 remaining] .........620 [1:32 remaining] .........630 [1:30 remaining] ..\n.......640 [1:27 remaining] .........650 [1:25 remaining] .........660 [1:22 remaining] .\n........670 [1:20 remaining] .........680 [1:17 remaining] .........690\n [1:15 remaining] .........700 [1:12 remaining] .........710 [1:10 remaining] .........\n720 [1:08 remaining] .........730 [1:05 remaining] .........740 [1:03 remaining] ........\n.750 [1:00 remaining] .........760 [58 sec remaining] .........770 [56 sec remaining] .......\n..780 [53 sec remaining] .........790 [51 sec remaining] .........800 [48 sec remaining] ......\n...810 [46 sec remaining] .........820 [43 sec remaining] .........830 [41 sec remaining] .....\n....840 [39 sec remaining] .........850 [36 sec remaining] .........860 [34 sec remaining] ....\n.....870 [31 sec remaining] .........880 [29 sec remaining] .........890 [26 sec remaining] ...\n......900 [24 sec remaining] .........910 [22 sec remaining] .........920 [19 sec remaining] ..\n.......930 [17 sec remaining] .........940 [14 sec remaining] .........950 [12 sec remaining] .\n........960 [9 sec remaining] .........970 [7 sec remaining] .........980\n [5 sec remaining] .........990 [2 sec remaining] ........\n999.\n\nDone.\n\nplot(L_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to compute spatial weights using R. By the end to this hands-on exercise, we will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#data-preparation",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Data Preparation",
    "text": "Data Preparation\nLet’s combine the geospatial data with the aspatial data\nLet’s take a look at the combined hunan data\n\n\n    NAME_2               ID_3          NAME_3           ENGTYPE_3        \n Length:88          Min.   :21098   Length:88          Length:88         \n Class :character   1st Qu.:21125   Class :character   Class :character  \n Mode  :character   Median :21150   Mode  :character   Mode  :character  \n                    Mean   :21150                                        \n                    3rd Qu.:21174                                        \n                    Max.   :21201                                        \n   Shape_Leng       Shape_Area         County              City          \n Min.   :0.7722   Min.   :0.02128   Length:88          Length:88         \n 1st Qu.:2.2533   1st Qu.:0.13669   Class :character   Class :character  \n Median :2.5844   Median :0.18564   Mode  :character   Mode  :character  \n Mean   :2.6057   Mean   :0.19274                                        \n 3rd Qu.:3.0994   3rd Qu.:0.23735                                        \n Max.   :4.5835   Max.   :0.53452                                        \n   avg_wage            deposite            FAI           Gov_Rev      \n Length:88          Min.   :  564.1   Min.   : 1005   Min.   : 108.4  \n Class :character   1st Qu.: 4306.9   1st Qu.: 3911   1st Qu.: 307.3  \n Mode  :character   Median : 6677.3   Median : 6854   Median : 455.2  \n                    Mean   : 7514.1   Mean   : 9021   Mean   : 646.7  \n                    3rd Qu.: 9502.6   3rd Qu.:10212   3rd Qu.: 637.3  \n                    Max.   :24332.0   Max.   :49234   Max.   :5350.0  \n    Gov_Exp            GDP            GDPPC            GIO        \n Min.   : 683.6   Min.   : 1490   Min.   : 8497   Min.   :   514  \n 1st Qu.:1451.7   1st Qu.: 5844   1st Qu.:14566   1st Qu.:  4965  \n Median :2037.0   Median :10483   Median :20433   Median : 10698  \n Mean   :2155.9   Mean   :14931   Mean   :24405   Mean   : 19227  \n 3rd Qu.:2638.1   3rd Qu.:19131   3rd Qu.:27224   3rd Qu.: 22223  \n Max.   :7885.5   Max.   :88009   Max.   :88656   Max.   :148976  \n      Loan           NIPCR            Bed            Emp        \n Min.   :  358   Min.   : 2895   Min.   : 392   Min.   : 73.65  \n 1st Qu.: 2242   1st Qu.: 3981   1st Qu.:1111   1st Qu.:231.56  \n Median : 3683   Median : 6119   Median :1642   Median :363.79  \n Mean   : 4687   Mean   : 7095   Mean   :1765   Mean   :388.71  \n 3rd Qu.: 5082   3rd Qu.: 9768   3rd Qu.:2240   3rd Qu.:525.04  \n Max.   :40534   Max.   :17070   Max.   :6225   Max.   :919.62  \n      EmpR           EmpRT          Pri_Stu          Sec_Stu      \n Min.   : 62.0   Min.   : 33.6   Min.   :  5.91   Min.   : 3.201  \n 1st Qu.:191.2   1st Qu.:105.5   1st Qu.: 24.09   1st Qu.:15.095  \n Median :284.2   Median :171.2   Median : 36.85   Median :24.834  \n Mean   :316.4   Mean   :190.4   Mean   : 43.08   Mean   :27.609  \n 3rd Qu.:433.5   3rd Qu.:263.5   3rd Qu.: 58.26   3rd Qu.:36.248  \n Max.   :757.6   Max.   :451.6   Max.   :112.20   Max.   :68.853  \n   Household       Household_R          NOIP           Pop_R      \n Min.   : 27.15   Min.   : 30.40   Min.   : 10.0   Min.   : 57.7  \n 1st Qu.: 99.15   1st Qu.: 87.95   1st Qu.: 47.0   1st Qu.:227.3  \n Median :162.85   Median :152.85   Median : 80.5   Median :348.7  \n Mean   :175.04   Mean   :159.62   Mean   :107.3   Mean   :369.3  \n 3rd Qu.:245.32   3rd Qu.:218.22   3rd Qu.:124.0   3rd Qu.:517.0  \n Max.   :391.70   Max.   :369.80   Max.   :733.0   Max.   :834.1  \n      RSCG             Pop_T             Agri            Service       \n Min.   :  354.5   Min.   :  92.3   Min.   :  527.2   Min.   :    5.2  \n 1st Qu.: 1757.2   1st Qu.: 333.1   1st Qu.: 2255.3   1st Qu.: 1576.1  \n Median : 3437.8   Median : 572.5   Median : 3700.7   Median : 5932.5  \n Mean   : 4164.7   Mean   : 586.8   Mean   : 4705.9   Mean   : 8678.9  \n 3rd Qu.: 5630.2   3rd Qu.: 792.0   3rd Qu.: 6312.9   3rd Qu.:11727.5  \n Max.   :22604.0   Max.   :1285.5   Max.   :18328.5   Max.   :53160.0  \n    Disp_Inc           RORP            ROREmp                geometry \n Min.   : 11954   Min.   :0.2357   Min.   :0.4545   POLYGON      :88  \n 1st Qu.: 14966   1st Qu.:0.5968   1st Qu.:0.7565   epsg:3414    : 0  \n Median : 18542   Median :0.6517   Median :0.8300   +proj=tmer...: 0  \n Mean   : 26133   Mean   :0.6298   Mean   :0.8037                     \n 3rd Qu.: 21774   3rd Qu.:0.6850   3rd Qu.:0.8653                     \n Max.   :183252   Max.   :0.7606   Max.   :0.9179                     \n\n\nNow we can make a basemap:\n\n\n\n\n\nTo see the GDPPC distribution on a map:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#queen-based",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#queen-based",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "QUEEN Based",
    "text": "QUEEN Based\nthe term QUEEN refers to a queen in chess, which can move to any points that are in contact, be it horizontal, vertical, or even diagonal. This means that in our computation, any region that is in contact is considered a neighbor, even if there is only a single point of contact between those regions.\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary shows that out of 88 area units in Hunan, with the most connected unit having 11 neighbours.\nTo access the name of the county of the first polygon:\n\n\n[1] \"Anxiang\"\n\n\nLet’s see the neighbors of the first polygon in the object\n\n\n[1]  2  3  4 57 85\n\n\nThe code chunk above returns the index of the neighbours of the first polygon in the object. To get the name of the regions, use the code chunk below\n\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nThe code chunk below is used to retrieve the GDPPC of the neighbours of the first polygon\n\n\n[1] 20981 34592 24473 21311 22879\n\n\nUse str() to display the complete weight matrix\n\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#rook-based",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#rook-based",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "ROOK Based",
    "text": "ROOK Based\nUnlike the queen, a rook can only move vertically or horizontally, with no diagonal movement. In this case, using a ROOK based (queen=FALSE) means that regions that only have a single point of contact is not considered a neighbor.\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nHere you can see that unlike the queen version, the rook method shows 85 regions with 10 links\nChecking the names of the neighbours of the first polygon\n\n\n[1] \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-contiguity-weights",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Visualising Contiguity Weights",
    "text": "Visualising Contiguity Weights\nA connectivity graph needs a point and displays a line to each neighboring point. As we are working with polygons in this exercise, we need to get points to draw the line. The most typical method is polygon centroids.\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package.\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\nNow we combine it with cbind\nCheck the first few observations\n\n\n     longitude latitude\n[1,]  836662.0  3175038\n[2,]  829886.4  3109750\n[3,]  810959.7  3176299\n[4,]  790539.4  3205555\n[5,]  783717.8  3176834\n\n\n\nPlotting Queen contiguity based neighbours map\n\n\n\n\n\n\n\nPlotting Rook contiguity based neighbours map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#identifying-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#identifying-cut-off-distance",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Identifying cut-off distance",
    "text": "Identifying cut-off distance\nSteps: 1. Return a matrix with indices of points that are k nearest neighbours using knearneigh() 2. Convert the knn object from knearneigh() to a list of class nb with a lost of integer vectors containing neighbour region id using knn2nb() 3. Return length of neigbour relationship edges using nbdists() 4. Remove the list structure of returned object using unlist()\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2251    6033    9870    9904   13825   17201"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Computing Fixed Distance Weight Matrix",
    "text": "Computing Fixed Distance Weight Matrix\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 0 \nPercentage nonzero weights: 0 \nAverage number of links: 0 \n88 regions with no links:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n76 77 78 79 80 81 82 83 84 85 86 87 88\n88 disjoint connected subgraphs\n\n\n\n\nList of 88\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n $ : int 0\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\nPlotting Fixed Distance Weight Matrix\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Computing Adaptive Distance Weight Matrix",
    "text": "Computing Adaptive Distance Weight Matrix\nAdaptive distance weight matrix takes into account that less densely settled areas (e.g. villages, countryside, etc) tend to have less neighbours, and more densely settled areas (big cities) tends to have more neighbours. Thus, we can use K-Nearest Neighbour to control the number of neighbours directly when we calculate the weight matrix\n\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 57 69\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 78 84\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 39 81\n $ : int [1:6] 25 27 30 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 34 36 39 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 74 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 50 51 52 53 54 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 65 76\n $ : int [1:6] 57 58 64 66 67 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 3 4 5 6 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 16 17 22 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 46 71 73 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 57 58 64 65 66 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 23 38 40 41 43 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 67 68 74\n $ : int [1:6] 1 2 3 5 56 69\n $ : int [1:6] 8 21 46 47 71 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\nPlotting Adaptive Distance Weight Matrix"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weight-matrix",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Row-Standardised Weight Matrix",
    "text": "Row-Standardised Weight Matrix\nNow, we assign weights to each neighboring polygon. The style=“W” argument refers to each neighboring polygon being assigned equal weight. This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. This way is the most intuitive way, but a huge drawback is that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. Other more robust options are availabe, such as using style=“B”.\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nzero.policy = TRUE allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset\nTo see the weights of the first polygon’s eight neighbors type:\n\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nwhen R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nCompare it with the style=“B” below\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn         S0           S1           S2\nB 88 7744 0.06196579 2.782761e-05 0.0002075265\n\n\n[[1]]\n[1] 7.791839e-05 1.721638e-04 1.009428e-04 1.616320e-04 9.865571e-05\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n5.083e-05 7.015e-05 9.887e-05 1.383e-04 1.582e-04 7.579e-04"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Spatial Lag With Row-Standardized Weights",
    "text": "Spatial Lag With Row-Standardized Weights\nSpatially lagged values here refers to average neighbor GDPPC value for each polygon.\n\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nNowe we retrieve the GDPPC of these five countries\n\n\n[1] 20981 34592 24473 21311 22879\n\n\nNow we append the lag list to hunan data\nNow let’s plot it to compare GDPPC and spatial lag GDPPC\n\n\n\n\n\nThe spatial lag GDPPC is the weighted average of the neighboring region’s GDPPC. Essentially, When interpreting spatial lag with row-standardized weights, you are looking at how much the GDPPC of neighboring regions contributes to the GDPPC of a given region"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-sum-of-neighboring-values",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-sum-of-neighboring-values",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Spatial Lag As Sum of Neighboring Values",
    "text": "Spatial Lag As Sum of Neighboring Values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights.\nFirst, we apply a value of 1 per each neighbor with lapply.\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nAfter assigning the proper weights, e can use lag.listw to compute a lag variable from our weight and GDPPC\nWe can append the output to our hunan data.\nLet’s compare the GDPPC with the lag sum"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Spatial Window Average",
    "text": "Spatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To add the diagonal element, we can use include.self() from spdep\n\n\n[1]  1  2  3  4 57 85\n\n\nNow we obtain weights with nb2listw()\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nNext, we just need to create the lag variable\n\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nAnd convert it into a data.frame and combine it with the hunan data\nCompare the lag GDPPC with the lag_window_average GDPPC with the kable() function from knitr\n\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((825339.4 3209148,…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((846673.4 3139165,…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((810038.7 3190827,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((756935.9 3225838,…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((783475.6 3207079,…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((708206.5 3241744,…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((1024633 3091569, …\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((900741.8 3060845,…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((906766.3 3077439,…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((959144.5 2890585,…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((1065564 2828411, …\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((893838.3 2764449,…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((910317.1 2744004,…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((1017476 2788033, …\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((977190.9 2763499,…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((976718.2 2845964,…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((1020609 2820527, …\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((904677 2861393, 9…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((948954.5 2932803,…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((916277.6 2904767,…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((897149.3 2958067,…\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((942592.9 2874262,…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((818150.6 2904520,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((659836.5 3027008,…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((631117.1 2970989,…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((634422.1 2901669,…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((623976.4 2862538,…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((615109.7 2998224,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((636593.9 2830511,…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((561722.2 2935313,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((704263.2 3039179,…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((723892.4 3117846,…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((625721.6 2957129,…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((787713 2989441, 7…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((861128.6 2981916,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((765661.4 3030736,…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((686942.1 2858390,…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((786516 2883527, 7…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((704480.6 2935185,…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((734695.4 2968915,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((827858.7 2945904,…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((678946.5 2903356,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((738995.8 2899208,…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((748750.9 2878860,…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((796346.4 2964043,…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((886350.3 3014311,…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((877379.7 3022683,…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((601273.4 3092068,…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((587249 3020500, 5…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((620888.1 3083237,…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((589011.7 3067928,…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((616595 3052847, 6…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((590246.8 3180293,…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((643343 3048504, 6…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((627795.4 3145425,…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((789009.7 3081509,…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((853111.1 3178170,…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((866754 3147605, 8…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((816357.7 2709600,…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((873168.1 2748284,…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((853845.3 2801658,…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((835079.5 2802787,…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((872752.4 2800712,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((909742.6 3208358,…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((970905.9 3211447,…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((922076.2 3134116,…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((1005450 3145461, …\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((915261.6 3129236,…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((711106.1 3194274,…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((1015909 2926248, …\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((988558.1 3018277,…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((1036591 2872725, …\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((995331 2959198, 9…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((956308.2 3024789,…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((681259.9 3160705,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((951297.3 3202661,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((797197.9 2878034,…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((832713.3 3088425,…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((788361.9 2932157,…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((800853.9 3014299,…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((652450.5 2943812,…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((911692.2 2904962,…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((955964.6 2803036,…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((925766.9 3023920,…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((828601.9 3161592,…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((936937.8 3008710,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((797995.7 2766682,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((787361.7 2718895,…\n\n\n\n\n\nAnd plot it to compare"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "title": "Hands On Exercise 4: Spatial Weights and Applications",
    "section": "Spatial Window Sum",
    "text": "Spatial Window Sum\nThe spatial window sum is similar to the window average, but we are not using the row-standardized weights.\n\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNow we can compare it with both kable() and qtm()\n\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n124236\nPOLYGON ((825339.4 3209148,…\n\n\nHanshou\n113624\n113624\nPOLYGON ((846673.4 3139165,…\n\n\nJinshi\n96573\n96573\nPOLYGON ((810038.7 3190827,…\n\n\nLi\n110950\n110950\nPOLYGON ((756935.9 3225838,…\n\n\nLinli\n109081\n109081\nPOLYGON ((783475.6 3207079,…\n\n\nShimen\n106244\n106244\nPOLYGON ((708206.5 3241744,…\n\n\nLiuyang\n174988\n174988\nPOLYGON ((1024633 3091569, …\n\n\nNingxiang\n235079\n235079\nPOLYGON ((900741.8 3060845,…\n\n\nWangcheng\n273907\n273907\nPOLYGON ((906766.3 3077439,…\n\n\nAnren\n256221\n256221\nPOLYGON ((959144.5 2890585,…\n\n\nGuidong\n98013\n98013\nPOLYGON ((1065564 2828411, …\n\n\nJiahe\n104050\n104050\nPOLYGON ((893838.3 2764449,…\n\n\nLinwu\n102846\n102846\nPOLYGON ((910317.1 2744004,…\n\n\nRucheng\n92017\n92017\nPOLYGON ((1017476 2788033, …\n\n\nYizhang\n133831\n133831\nPOLYGON ((977190.9 2763499,…\n\n\nYongxing\n158446\n158446\nPOLYGON ((976718.2 2845964,…\n\n\nZixing\n141883\n141883\nPOLYGON ((1020609 2820527, …\n\n\nChangning\n119508\n119508\nPOLYGON ((904677 2861393, 9…\n\n\nHengdong\n150757\n150757\nPOLYGON ((948954.5 2932803,…\n\n\nHengnan\n153324\n153324\nPOLYGON ((916277.6 2904767,…\n\n\nHengshan\n113593\n113593\nPOLYGON ((897149.3 2958067,…\n\n\nLeiyang\n129594\n129594\nPOLYGON ((942592.9 2874262,…\n\n\nQidong\n142149\n142149\nPOLYGON ((818150.6 2904520,…\n\n\nChenxi\n100119\n100119\nPOLYGON ((659836.5 3027008,…\n\n\nZhongfang\n82884\n82884\nPOLYGON ((631117.1 2970989,…\n\n\nHuitong\n74668\n74668\nPOLYGON ((634422.1 2901669,…\n\n\nJingzhou\n43184\n43184\nPOLYGON ((623976.4 2862538,…\n\n\nMayang\n99244\n99244\nPOLYGON ((615109.7 2998224,…\n\n\nTongdao\n46549\n46549\nPOLYGON ((636593.9 2830511,…\n\n\nXinhuang\n20518\n20518\nPOLYGON ((561722.2 2935313,…\n\n\nXupu\n140576\n140576\nPOLYGON ((704263.2 3039179,…\n\n\nYuanling\n121601\n121601\nPOLYGON ((723892.4 3117846,…\n\n\nZhijiang\n92069\n92069\nPOLYGON ((625721.6 2957129,…\n\n\nLengshuijiang\n43258\n43258\nPOLYGON ((787713 2989441, 7…\n\n\nShuangfeng\n144567\n144567\nPOLYGON ((861128.6 2981916,…\n\n\nXinhua\n132119\n132119\nPOLYGON ((765661.4 3030736,…\n\n\nChengbu\n51694\n51694\nPOLYGON ((686942.1 2858390,…\n\n\nDongan\n59024\n59024\nPOLYGON ((786516 2883527, 7…\n\n\nDongkou\n69349\n69349\nPOLYGON ((704480.6 2935185,…\n\n\nLonghui\n73780\n73780\nPOLYGON ((734695.4 2968915,…\n\n\nShaodong\n94651\n94651\nPOLYGON ((827858.7 2945904,…\n\n\nSuining\n100680\n100680\nPOLYGON ((678946.5 2903356,…\n\n\nWugang\n69398\n69398\nPOLYGON ((738995.8 2899208,…\n\n\nXinning\n52798\n52798\nPOLYGON ((748750.9 2878860,…\n\n\nXinshao\n140472\n140472\nPOLYGON ((796346.4 2964043,…\n\n\nShaoshan\n118623\n118623\nPOLYGON ((886350.3 3014311,…\n\n\nXiangxiang\n180933\n180933\nPOLYGON ((877379.7 3022683,…\n\n\nBaojing\n82798\n82798\nPOLYGON ((601273.4 3092068,…\n\n\nFenghuang\n83090\n83090\nPOLYGON ((587249 3020500, 5…\n\n\nGuzhang\n97356\n97356\nPOLYGON ((620888.1 3083237,…\n\n\nHuayuan\n59482\n59482\nPOLYGON ((589011.7 3067928,…\n\n\nJishou\n77334\n77334\nPOLYGON ((616595 3052847, 6…\n\n\nLongshan\n38777\n38777\nPOLYGON ((590246.8 3180293,…\n\n\nLuxi\n111463\n111463\nPOLYGON ((643343 3048504, 6…\n\n\nYongshun\n74715\n74715\nPOLYGON ((627795.4 3145425,…\n\n\nAnhua\n174391\n174391\nPOLYGON ((789009.7 3081509,…\n\n\nNan\n150558\n150558\nPOLYGON ((853111.1 3178170,…\n\n\nYuanjiang\n122144\n122144\nPOLYGON ((866754 3147605, 8…\n\n\nJianghua\n68012\n68012\nPOLYGON ((816357.7 2709600,…\n\n\nLanshan\n84575\n84575\nPOLYGON ((873168.1 2748284,…\n\n\nNingyuan\n143045\n143045\nPOLYGON ((853845.3 2801658,…\n\n\nShuangpai\n51394\n51394\nPOLYGON ((835079.5 2802787,…\n\n\nXintian\n98279\n98279\nPOLYGON ((872752.4 2800712,…\n\n\nHuarong\n47671\n47671\nPOLYGON ((909742.6 3208358,…\n\n\nLinxiang\n26360\n26360\nPOLYGON ((970905.9 3211447,…\n\n\nMiluo\n236917\n236917\nPOLYGON ((922076.2 3134116,…\n\n\nPingjiang\n220631\n220631\nPOLYGON ((1005450 3145461, …\n\n\nXiangyin\n185290\n185290\nPOLYGON ((915261.6 3129236,…\n\n\nCili\n64640\n64640\nPOLYGON ((711106.1 3194274,…\n\n\nChaling\n70046\n70046\nPOLYGON ((1015909 2926248, …\n\n\nLiling\n126971\n126971\nPOLYGON ((988558.1 3018277,…\n\n\nYanling\n144693\n144693\nPOLYGON ((1036591 2872725, …\n\n\nYou\n129404\n129404\nPOLYGON ((995331 2959198, 9…\n\n\nZhuzhou\n284074\n284074\nPOLYGON ((956308.2 3024789,…\n\n\nSangzhi\n112268\n112268\nPOLYGON ((681259.9 3160705,…\n\n\nYueyang\n203611\n203611\nPOLYGON ((951297.3 3202661,…\n\n\nQiyang\n145238\n145238\nPOLYGON ((797197.9 2878034,…\n\n\nTaojiang\n251536\n251536\nPOLYGON ((832713.3 3088425,…\n\n\nShaoyang\n108078\n108078\nPOLYGON ((788361.9 2932157,…\n\n\nLianyuan\n238300\n238300\nPOLYGON ((800853.9 3014299,…\n\n\nHongjiang\n108870\n108870\nPOLYGON ((652450.5 2943812,…\n\n\nHengyang\n108085\n108085\nPOLYGON ((911692.2 2904962,…\n\n\nGuiyang\n262835\n262835\nPOLYGON ((955964.6 2803036,…\n\n\nChangsha\n248182\n248182\nPOLYGON ((925766.9 3023920,…\n\n\nTaoyuan\n244850\n244850\nPOLYGON ((828601.9 3161592,…\n\n\nXiangtan\n404456\n404456\nPOLYGON ((936937.8 3008710,…\n\n\nDao\n67608\n67608\nPOLYGON ((797995.7 2766682,…\n\n\nJiangyong\n33860\n33860\nPOLYGON ((787361.7 2718895,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "we will learn how to compute Global and Local Measures of Spatial Autocorrelation (GMSA) by using spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#packages",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Packages",
    "text": "Packages\nUse this chunk to load the required packages\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Data",
    "text": "Data\nWe are using these data: - Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format. - Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\nLoading Data\nWe will use st_read() for the geospatial data, and read_csv() for the aspatial data\n\nhunan &lt;- st_read(dsn=\"data/geospatial\", layer='Hunan')\n\nReading layer `Hunan' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\nJoining data\nWe will use left_join() to combine the two data\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  dplyr::select(1:4, 7, 15)\n\n\n\nVisualization\nWe will use qtm() to prepare a basemap and a cloropeth map showing distribution of GDPPC 2012\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nWe need to construct a spatial weights of the study area first. We can use poly2nb() to do that. The code chunk below computes Queen contiguity weight matrix\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Row-standardised Weight Matrix",
    "text": "Row-standardised Weight Matrix\nNext, we can assign weights to the neighbouring polygon. This study will use equal weight (style=‘W’)\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-test",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran’s Test",
    "text": "Moran’s Test\nWe will learn how to use moran.test() from spdep\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nMonte Carlo Moran’s\nmoran.mc() can perform monte carlo simulation of the Moran’s test\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualization\nTo understand more about the test result, we can first get some statistical measures with summary()\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nThen, we can also plot a histogram with hist()\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gearys-c",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Geary’s C",
    "text": "Geary’s C\nWe are also learning geary.test() from spdep\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nMonte Carlo Geary’s Test\ngeary.mc() can perform monte carlo simulation of the Moran’s test\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualization\nTo understand more about the test result, we can first get some statistical measures with summary()\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nThen, we can also plot a histogram with hist()\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Geary C\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#spatial-correlogram",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlogram is used to examine patterns, showing how correlated are paris of spatial observations when we increase the distance\n\nMoran’s I correlogram\nWe can use sp.correlogram with method=“I”\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\nGeary’s C correlogram\nWe can use sp.correlogram with method=“I”\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#local-morans-i",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Local Moran’s I",
    "text": "Local Moran’s I\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nMapping local Moran’s I values\nBefore mapping, it is wse to append the local Moran’s I dataframe to hunan SpatialolygonDataFrame\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nNow we can plot the local values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping local Moran’s p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran Scatterplot",
    "text": "Moran Scatterplot\nWe can use moran.plot()\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#moran-scatterplot-with-standardised-variable",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran scatterplot with standardised variable",
    "text": "Moran scatterplot with standardised variable\nFirst we can use scale() to scale the variables\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow we can plot it with this method\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-lisa-map-classes",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Preparing LISA map classes",
    "text": "Preparing LISA map classes\nFirst, we set a quadrant object.Next, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#lisa-map",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "LISA map",
    "text": "LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Getis and Ord’s G-Statistics",
    "text": "Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#distance-based-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#distance-based-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Distance-Based Weight Matrix",
    "text": "Distance-Based Weight Matrix\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#determining-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#determining-cut-off-distance",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Determining Cut Off Distance",
    "text": "Determining Cut Off Distance\nStep-by-step: 1. Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep. 2. Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb(). 3. Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise. 4. Remove the list structure of the returned object by using unlist().\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-fixed-distance-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Fixed Distance Weight Matrix",
    "text": "Computing Fixed Distance Weight Matrix\nWe can use dnearneigh() to get the weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAnd convert it into spatial weights object with nb2listw()\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Adaptive Distance Weight Matrix",
    "text": "Computing Adaptive Distance Weight Matrix\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nAnd convert it into spatial weights object with nb2listw()\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#fixed-distance",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#fixed-distance",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Fixed Distance",
    "text": "Fixed Distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\n\nCombine it to hunan sf data frame\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\nMapping Gi Values\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#adaptive-distance",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#adaptive-distance",
    "title": "Hands On Exercise 5: Global and Local Measures of Spatial Autocorrelation",
    "section": "Adaptive Distance",
    "text": "Adaptive Distance\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\nCombine it to hunan sf data frame\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\nMapping Gi Values\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "we will learn how to compute Global and Local Measures of Spatial Autocorrelation (GMSA) by using spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#packages",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Packages",
    "text": "Packages\nUse this chunk to load the required packages\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Data",
    "text": "Data\nWe are using these data: - Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format. - Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\nLoading Data\nWe will use st_read() for the geospatial data, and read_csv() for the aspatial data\n\nhunan &lt;- st_read(dsn=\"data/geospatial\", layer='Hunan')\n\nReading layer `Hunan' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\nJoining data\nWe will use left_join() to combine the two data\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\nVisualization\nWe will use qtm() to prepare a basemap and a cloropeth map showing distribution of GDPPC 2012\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-contiguity-spatial-weights",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nWe need to construct a spatial weights of the study area first. We can use poly2nb() to do that. The code chunk below computes Queen contiguity weight matrix\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#row-standardised-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#row-standardised-weight-matrix",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Row-standardised Weight Matrix",
    "text": "Row-standardised Weight Matrix\nNext, we can assign weights to the neighbouring polygon. This study will use equal weight (style=‘W’)\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#morans-test",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#morans-test",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran’s Test",
    "text": "Moran’s Test\nWe will learn how to use moran.test() from spdep\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nMonte Carlo Moran’s\nmoran.mc() can perform monte carlo simulation of the Moran’s test\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualization\nTo understand more about the test result, we can first get some statistical measures with summary()\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nThen, we can also plot a histogram with hist()\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#gearys-c",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Geary’s C",
    "text": "Geary’s C\nWe are also learning geary.test() from spdep\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nMonte Carlo Geary’s Test\ngeary.mc() can perform monte carlo simulation of the Moran’s test\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualization\nTo understand more about the test result, we can first get some statistical measures with summary()\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nThen, we can also plot a histogram with hist()\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Geary C\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlogram is used to examine patterns, showing how correlated are paris of spatial observations when we increase the distance\n\nMoran’s I correlogram\nWe can use sp.correlogram with method=“I”\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\nGeary’s C correlogram\nWe can use sp.correlogram with method=“I”\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-morans-i",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Local Moran’s I",
    "text": "Local Moran’s I\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nMapping local Moran’s I values\nBefore mapping, it is wse to append the local Moran’s I dataframe to hunan SpatialolygonDataFrame\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nNow we can plot the local values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping local Moran’s p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#moran-scatterplot",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran Scatterplot",
    "text": "Moran Scatterplot\nWe can use moran.plot()\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#moran-scatterplot-with-standardised-variable",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Moran scatterplot with standardised variable",
    "text": "Moran scatterplot with standardised variable\nFirst we can use scale() to scale the variables\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow we can plot it with this method\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#preparing-lisa-map-classes",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Preparing LISA map classes",
    "text": "Preparing LISA map classes\nFirst, we set a quadrant object.Next, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#lisa-map",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "LISA map",
    "text": "LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getis-and-ords-g-statistics",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Getis and Ord’s G-Statistics",
    "text": "Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#distance-based-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#distance-based-weight-matrix",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Distance-Based Weight Matrix",
    "text": "Distance-Based Weight Matrix\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determining-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determining-cut-off-distance",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Determining Cut Off Distance",
    "text": "Determining Cut Off Distance\nStep-by-step: 1. Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep. 2. Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb(). 3. Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise. 4. Remove the list structure of the returned object by using unlist().\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-fixed-distance-weight-matrix",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Fixed Distance Weight Matrix",
    "text": "Computing Fixed Distance Weight Matrix\nWe can use dnearneigh() to get the weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAnd convert it into spatial weights object with nb2listw()\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Computing Adaptive Distance Weight Matrix",
    "text": "Computing Adaptive Distance Weight Matrix\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nAnd convert it into spatial weights object with nb2listw()\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#fixed-distance",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#fixed-distance",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Fixed Distance",
    "text": "Fixed Distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\n\nCombine it to hunan sf data frame\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\nMapping Gi Values\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#adaptive-distance",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#adaptive-distance",
    "title": "Hands On Exercise 6: Global and Local Measures of Spatial Autocorrelation",
    "section": "Adaptive Distance",
    "text": "Adaptive Distance\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\nCombine it to hunan sf data frame\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\nMapping Gi Values\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely: - hierarchical cluster analysis; and - spatially constrained cluster analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-geospatial-data",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nWe will use st_read to save the geospatial data to a variable called shan_sf, and use summary() to get a feel of the dataset"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-aspatial-data",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Importing Aspatial Data",
    "text": "Importing Aspatial Data\nFor the aspatial data, we will use read_csv()\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#eda",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#eda",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "EDA",
    "text": "EDA\n\nHistogram\nHistogram is useful to know the distribution of the data.\nHere, we will see the distribution of the original RADIO\nAnd here we will see the distribution of the derived RADIO_PR\nHere is all the histograms for the derived variables\n\n\nBoxplot\nBoxplot is useful to detect outliers\nWe can look at the RADIO variable\nHere we are looking at the derived RADIO_PR\n\n\nChoropleth\n\nJoining geospatial and aspatial data\nBefore we can make a choropleth map, we need to combine the geospatial and aspatial data. We can use left_join() to do so, based on the TS_PCODE column\nThe combined data is saved into an rds file, which we can call with read_rds()\n\n\nPreparing choropleth\nWe can use qtm() to quickly make a choropleth\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map)\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#extracting-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#extracting-cluster-analysis",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "1. Extracting Cluster Analysis",
    "text": "1. Extracting Cluster Analysis\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\nThe final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nWe need to change the rows by township name instead of row number, so that we can call the rows by the township name"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data-standardisation",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2. Data Standardisation",
    "text": "2. Data Standardisation\n\nMin-Max Standardisation\nnormalize() uses min-max method to standardize the data. The min-max standardized variables will then turn to be between 0-1\n\n\nZ-Score Standardisation\nscale() will standardizes data using Z-score methods. The mean and standard deviation of the Z-score standardized variables will be 0 and 1 respectively. Z-score standardisation should only be used if we are sure that the data is normally distributed\n\n\nVisualising Standardised Clustering Variables\nIt is good practice to visualise the distribution.\nWith histogram:\nWith density plot:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-proximity-matrix",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3. Computing Proximity Matrix",
    "text": "3. Computing Proximity Matrix\nWe will use dist() from R to compute the proximity matrix. dist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-hieararchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-hieararchical-clustering",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4. Computing Hieararchical Clustering",
    "text": "4. Computing Hieararchical Clustering\nWe will use hclust() to compute hieararchical clustering function. hclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#gap-statistic-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#gap-statistic-method",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Gap Statistic Method",
    "text": "Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.We can use clusGap() from the cluster package\nthe hcut function used inside is taken from factoextra. Also from factoextra, we can use fvis_gap_stat() to visualize the plot\nBased on the plot, the recommended number of cluster is 1 (highest Gap statistic)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#transform-data-to-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#transform-data-to-matrix",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Transform Data to Matrix",
    "text": "Transform Data to Matrix\nTo make our heatmap, we need to convert the data into a matrix"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-with-heatmaply",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-with-heatmaply",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Plotting With heatmaply()",
    "text": "Plotting With heatmaply()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#convert-into-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#convert-into-spatialpolygonsdataframe",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "1. Convert into SpatialPolygonsDataFrame",
    "text": "1. Convert into SpatialPolygonsDataFrame\nskater() only supports sp objects"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#compute-neighbour-list",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#compute-neighbour-list",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2. Compute Neighbour List",
    "text": "2. Compute Neighbour List\nWe will use poly2nd() to compute neighbours list"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-minimum-spanning-tree",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#computing-minimum-spanning-tree",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3. Computing Minimum Spanning Tree",
    "text": "3. Computing Minimum Spanning Tree\nFirst, we calculate the cost of each edge with nbcosts()\nNext, we incorporate these costs into a weights object with nb2listw(). We set style as B to make sure the cost values are not row-standardised\nBased on the weights, the spanning tree is computed by mstree()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#compating-spatially-constrained-clusters-with-skater-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#compating-spatially-constrained-clusters-with-skater-method",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4. Compating Spatially Constrained Clusters With SKATER Method",
    "text": "4. Compating Spatially Constrained Clusters With SKATER Method\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters. The result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\nWe can check the cluster assignment\nAnd find out how many observations are in each cluster"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-the-clusters-in-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-the-clusters-in-choropleth-map",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "5. Visualising The CLusters In Choropleth Map",
    "text": "5. Visualising The CLusters In Choropleth Map\nFor easy comparison:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Ward-like Hierarchical Clustering: ClustGeo",
    "text": "Ward-like Hierarchical Clustering: ClustGeo\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#mapping-the-formed-clusters-1",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#mapping-the-formed-clusters-1",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Mapping The Formed Clusters",
    "text": "Mapping The Formed Clusters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#individual-clustering-variable",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#individual-clustering-variable",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Individual Clustering Variable",
    "text": "Individual Clustering Variable\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multivariate",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multivariate",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Multivariate",
    "text": "Multivariate\nWe can use parallel coordinate plot to reveal clustering variables. We will use ggparcoord() from Gally\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nWe can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.In the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Geospatial Data",
    "text": "Geospatial Data\nWe will use the MP14_SUBZONE_WEB_PL for the geospatial data.\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nDon’t forget to check the crs and update it if needed\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#aspatial-data",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Aspatial Data",
    "text": "Aspatial Data\nWe can use read_csv() to read the csv file for the aspatial data\n\n\n# A tibble: 6 × 23\n  LATITUDE LONGITUDE POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD\n     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     1.29      104.   118635       3000000      309    30     7.94\n2     1.33      104.   288420       3880000      290    32     6.61\n3     1.31      104.   267833       3325000      248    33     6.90\n4     1.31      104.   258380       4250000      127     7     4.04\n5     1.32      104.   467169       1400000      145    28    11.8 \n6     1.31      104.   466472       1320000      139    22    10.3 \n# ℹ 16 more variables: PROX_CHILDCARE &lt;dbl&gt;, PROX_ELDERLYCARE &lt;dbl&gt;,\n#   PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;\n\n\nWe will convert the tibble data to a sf using st_as_sf() abd transform the crs from 4326, since the geometry comes from lat and long, to 3414 for Singapore’s crs\n\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graphics",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "EDA using statistical graphics",
    "text": "EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\n\n\n\n\nThe distribution is right-skewed. Statistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Multiple Histogram Plots distribution of variables",
    "text": "Multiple Histogram Plots distribution of variables\nWe will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Drawing Statistical Point Map",
    "text": "Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\n\n\n\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Simple Linear Regression Method",
    "text": "Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n  *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Multiple Linear Regression Method",
    "text": "Multiple Linear Regression Method\n\nVisualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\nBuilding a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-olsrr-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Preparing Publication Quality Table: olsrr method",
    "text": "Preparing Publication Quality Table: olsrr method\nWe will revise the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below\n\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-gtsummary-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-gtsummary-method",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Preparing Publication Quality Table: gtsummary method",
    "text": "Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression repor\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\nChecking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\nTest for non-linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for normality assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\nTest for spatial autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\nNext, we will join the newly created data frame with condo_resale.sf object.\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\n\n\n\n\n\n\nswitch back to “plot” mode before continue.\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 2.2e-16 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands On Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Building Fixed Bandwidth GWR Model",
    "text": "Building Fixed Bandwidth GWR Model\n\nComputing fixed bandwidth\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres\n\nGWModel method - fixed bandwidth\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-25 03:37:23.967079 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-03-25 03:37:24.630056 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\nBuilding Adaptive Bandwidth GWR Model\n\nComputing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\nConstructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\nThe code below can be used to display the model output.\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-25 03:37:29.558478 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-03-25 03:37:30.335525 \n\n\n\n\n\nVisualizing GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\nConverting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\nVisualizing local R2\nThe code chunks below is used to create an interactive point symbol map.\n\n\n\n\n\n\n\n\n\nVisualizing coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy URA Planning Region"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-sampling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-sampling",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Data Sampling",
    "text": "Data Sampling\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\nSave the split datasets to rds format"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-correlation-matrix",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Computing Correlation Matrix",
    "text": "Computing Correlation Matrix\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Building a non-spatial multiple linear regression",
    "text": "Building a non-spatial multiple linear regression"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#convert-sf-train-data-to-spatialpoint",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#convert-sf-train-data-to-spatialpoint",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Convert sf train data to SpatialPoint",
    "text": "Convert sf train data to SpatialPoint"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-adaptive-bandwidth",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Computing adaptive bandwidth",
    "text": "Computing adaptive bandwidth\nConstructing adaptive bandwidth GWR model"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#convert-sf-test-data-to-spatialpoint",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#convert-sf-test-data-to-spatialpoint",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Convert sf test data to SpatialPoint",
    "text": "Convert sf test data to SpatialPoint"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-adaptive-bandwidth-for-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#computing-adaptive-bandwidth-for-test-data",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Computing adaptive bandwidth for test data",
    "text": "Computing adaptive bandwidth for test data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#dropping-geometry-field",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#dropping-geometry-field",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Dropping geometry field",
    "text": "Dropping geometry field\nFirst, we will drop geometry column of the sf data.frame by using st_drop_geometry() of sf package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#calibrating-with-training-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#calibrating-with-training-data",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Calibrating with training data",
    "text": "Calibrating with training data\nThe code chunk below calibrate a geographic ranform forest model by using grf() of SpatialML package.\nLet’s save the model output by using the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#converting-the-predicted-output-into-a-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#converting-the-predicted-output-into-a-dataframe",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Converting the predicted output into a dataframe",
    "text": "Converting the predicted output into a dataframe\nThe output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualizing-predicted-values",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualizing-predicted-values",
    "title": "Hands On Exercise 9: Geographically Weighted Predictive Models",
    "section": "Visualizing predicted values",
    "text": "Visualizing predicted values\nAlternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/ELDERCARE.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/ELDERCARE.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/hexagons.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/hexagons.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to model geographical accessibility by using R’s geospatial analysis packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-geospatial-data",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Importing geospatial data",
    "text": "Importing geospatial data\nThree geospatial data will be imported from the data/geospatial sub-folder. They are MP14_SUBZONE_NO_SEA_PL, hexagons and ELDERCARE.\nThe code chunk below is used to import these three data sets shapefile by using st_read() of sf packages.\n\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nReading layer `hexagons' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\n\nReading layer `ELDERCARE' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#updating-crs-information",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Updating CRS information",
    "text": "Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\nAfter transforming the projection metadata, you can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#cleaning-and-updating-attribute-fields-of-the-geospatial-data",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Cleaning and updating attribute fields of the geospatial data",
    "text": "Cleaning and updating attribute fields of the geospatial data\nThere are many redundant fields in the data tables of both eldercare and hexagons. The code chunks below will be used to exclude those redundant fields. At the same time, a new field called demand and a new field called capacity will be added into the data table of hexagons and eldercare sf data frame respectively. Both fields are derive using mutate() of dplyr package.\nNotice that for the purpose of this hands-on exercise, a constant value of 100 is used. In practice, actual demand of the hexagon and capacity of the eldercare centre should be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#importing-distance-matrix",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Importing Distance Matrix",
    "text": "Importing Distance Matrix\nThe code chunk below uses read_cvs() of readr package to import OD_Matrix.csv into RStudio. The imported object is a tibble data.frame called ODMatrix."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#tidying-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#tidying-distance-matrix",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Tidying distance matrix",
    "text": "Tidying distance matrix\nThe code chunk below uses spread() of tidyr package is used to transform the O-D matrix from a thin format into a fat format.\nNote: Since tidyr version 1.0 a new function called pivot_wider() is introduce. You should use pivot_wider() instead of spread()\nCurrently, the distance is measured in metre because SVY21 projected coordinate system is used. The code chunk below will be used to convert the unit f measurement from metre to kilometre."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#computing-hansens-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#computing-hansens-accessibility",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Computing Hansen’s accessibility",
    "text": "Computing Hansen’s accessibility\nNow, we ready to compute Hansen’s accessibility by using ac() of SpatialAcc package. Before getting started, you are encourage to read the arguments of the function at least once in order to ensure that the required inputs are available.\nThe code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_Handsen.\nThe default field name is very messy, we will rename it to accHansen by using the code chunk below.\nNotice that the field name is much more tidier now.\nNext, we will convert the data table into tibble format by using the code chunk below.\nLastly, bind_cols() of dplyr will be used to join the acc_Hansen tibble data frame with the hexagons simple feature data frame. The output is called hexagon_Hansen.\nNotice that hexagon_Hansen is a simple feature data frame and not a typical tibble data frame.\nActually, the steps above can be perform by using a single code chunk as shown below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#visualising-hansens-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#visualising-hansens-accessibility",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Visualising Hansen’s accessibility",
    "text": "Visualising Hansen’s accessibility\n\nExtracting map extend\nFirstly, we will extract the extend of hexagons simple feature data frame by by using st_bbox() of sf package.\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#statistical-graphic-visualisation",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#statistical-graphic-visualisation",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Statistical graphic visualisation",
    "text": "Statistical graphic visualisation\nIn this section, we are going to compare the distribution of Hansen’s accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into haxegon_Hansen simple feature data frame by using the code chunk below.\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#computing-kd2sfcas-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#computing-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Computing KD2SFCA’s accessibility",
    "text": "Computing KD2SFCA’s accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk. The code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_KD2SFCA. Notice that KD2SFCA is used for family argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#visualising-kd2sfcas-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#visualising-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Visualising KD2SFCA’s accessibility",
    "text": "Visualising KD2SFCA’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#statistical-graphic-visualisation-1",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#statistical-graphic-visualisation-1",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Statistical graphic visualisation",
    "text": "Statistical graphic visualisation\nNow, we are going to compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_KD2SFCA simple feature data frame by using the code chunk below.\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#computing-sam-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#computing-sam-accessibility",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Computing SAM accessibility",
    "text": "Computing SAM accessibility\nIn this section, you are going to repeat most of the steps you had learned in previous section to perform the analysis. However, some of the codes will be combined into one code chunk. The code chunk below calculates Hansen’s accessibility using ac() of SpatialAcc and data.frame() is used to save the output in a data frame called acc_SAM. Notice that SAM is used for family argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#visualising-sams-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#visualising-sams-accessibility",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Visualising SAM’s accessibility",
    "text": "Visualising SAM’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#statistical-graphic-visualisation-2",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex10.html#statistical-graphic-visualisation-2",
    "title": "Hands-on Exercise 10: Modelling Geographical Accessibility",
    "section": "Statistical graphic visualisation",
    "text": "Statistical graphic visualisation\nNow, we are going to compare the distribution of SAM accessibility values by URA Planning Region.\nFirstly, we need to add the planning region field into hexagon_SAM simple feature data frame by using the code chunk below.\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 02",
    "section": "",
    "text": "In this in-class exercise, we will be using these packages:\n\nsf\ntmap\ntidyverse\narrow\nlubridate\n\n\npacman::p_load(sf, tmap, tidyverse, arrow, lubridate)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-packages",
    "title": "In-class Exercise 02",
    "section": "",
    "text": "In this in-class exercise, we will be using these packages:\n\nsf\ntmap\ntidyverse\narrow\nlubridate\n\n\npacman::p_load(sf, tmap, tidyverse, arrow, lubridate)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-data",
    "title": "In-class Exercise 02",
    "section": "Loading Data",
    "text": "Loading Data\nUsing the read_parquet() function from the arrow package to load the .parquet data into a file called df\n\ndf &lt;- read_parquet('data/GrabPosisi/part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet')\n\nWe noticed that pingtimestamp is an integer field, so we need to convert pingtimestamp field to a datetime format (POCIXCT)\n\ndf$pingtimestamp &lt;- as_datetime(df$pingtimestamp)\n\nNow, we save the df into a .rds file\n\nwrite_rds(df, 'data/rds/part0.rds')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-trip-starting-locations",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-trip-starting-locations",
    "title": "In-class Exercise 02",
    "section": "Extracting trip starting locations",
    "text": "Extracting trip starting locations\n\nExtract trip origin locations\nDerive 3 new columns for weekday, starting hour, and day of the month\nName the output tibble data.frame origin_df\n\n\norigin_df &lt;- df |&gt; \n  group_by(trj_id) |&gt; \n  arrange(pingtimestamp) |&gt;\n  filter(row_number()==1) |&gt;\n  mutate(weekday = wday(pingtimestamp, \n                        label = TRUE, \n                        abbr=TRUE), \n         starting_hour = factor(hour(pingtimestamp)), \n         day = factor(mday(pingtimestamp)))\n\nNow we extract the trip’s destination locations\n\n#Same approach, but in descending order\ndestination_df &lt;- df |&gt; \n  group_by(trj_id) |&gt; \n  arrange(desc(pingtimestamp)) |&gt;\n  filter(row_number()==1) |&gt;\n  mutate(weekday = wday(pingtimestamp, \n                        label = TRUE, \n                        abbr=TRUE), \n         ending_hour = factor(hour(pingtimestamp)), \n         day = factor(mday(pingtimestamp)))\n\nSave the data to .rds"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#import-data-from-rds-if-needed",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#import-data-from-rds-if-needed",
    "title": "In-class Exercise 02",
    "section": "Import data from RDS if needed",
    "text": "Import data from RDS if needed\n\norigin_df &lt;- read_rds('data/rds/origin_df.rds')\ndestination_df &lt;- read_rds('data/rds/destination_df.rds')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-Network.html#loading-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-Network.html#loading-data",
    "title": "In-class Exercise 03 - Network Constrained Spatial Point Analysis",
    "section": "Loading Data",
    "text": "Loading Data\n\n\nReading layer `Punggol_St' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\nReading layer `Punggol_CC' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\n\n\n\n\n\n\n\n\nLixelize\nLength of lixel = 750 Minimum length of lixel = 375 mindist should be half of length"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-Network.html#generating-line-centre-points",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-Network.html#generating-line-centre-points",
    "title": "In-class Exercise 03 - Network Constrained Spatial Point Analysis",
    "section": "Generating line centre points",
    "text": "Generating line centre points\nWe can use lines_center() of spNetwork"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03-Network.html#performing-nkde",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03-Network.html#performing-nkde",
    "title": "In-class Exercise 03 - Network Constrained Spatial Point Analysis",
    "section": "Performing NKDE",
    "text": "Performing NKDE\nBe careful of kernel methods and bandwidth. They are the most important.\n\nVisualizing NKDE\nInsert the densities to samples and lixels (with additional rescaling)\nThen, plot it"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-packages",
    "title": "In-class Exercise 03",
    "section": "Loading packages",
    "text": "Loading packages"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-data",
    "title": "In-class Exercise 03",
    "section": "Loading Data",
    "text": "Loading Data\n\n\nReading layer `ChildCareServices' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial\\ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex03\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#creating-coastal-outline",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#creating-coastal-outline",
    "title": "In-class Exercise 03",
    "section": "Creating Coastal outline",
    "text": "Creating Coastal outline"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#geospatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#geospatial-data-wrangling",
    "title": "In-class Exercise 03",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nConverting to SP from SF\n\n\nConverting to PPP from SF\nWith as.ppp, we can convert to PPP without manually converting to SP first\n\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1925 character character \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\nHandling Duplicates\nCheck for duplication with any(duplicated())\n\n\n[1] FALSE\n\n\nTo count the number of co-incidence point, we use multiplicity()\n\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1555] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1592] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1629] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1666] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1703] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1740] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1777] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1814] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1851] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1888] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1925] 1\n\n\n\n\nCreating owin\nowin confines the data points to a certain area\nbefore using owin, the map is not confined. With owin, we can focus on the land of Singapore\n\n\nWindow: polygonal boundary\n80 separate polygons (35 holes)\n                  vertices         area relative.area\npolygon 1            14650  6.97996e+08      8.93e-01\npolygon 2 (hole)         3 -2.21090e+00     -2.83e-09\npolygon 3              285  1.61128e+06      2.06e-03\npolygon 4 (hole)         3 -2.05920e-03     -2.63e-12\npolygon 5 (hole)         3 -8.83647e-03     -1.13e-11\npolygon 6              668  5.40368e+07      6.91e-02\npolygon 7               44  2.26577e+03      2.90e-06\npolygon 8               27  1.50315e+04      1.92e-05\npolygon 9              711  1.28815e+07      1.65e-02\npolygon 10 (hole)       36 -4.01660e+04     -5.14e-05\npolygon 11 (hole)      317 -5.11280e+04     -6.54e-05\npolygon 12 (hole)        3 -3.41405e-01     -4.37e-10\npolygon 13 (hole)        3 -2.89050e-05     -3.70e-14\npolygon 14              77  3.29939e+05      4.22e-04\npolygon 15              30  2.80002e+04      3.58e-05\npolygon 16 (hole)        3 -2.83151e-01     -3.62e-10\npolygon 17              71  8.18750e+03      1.05e-05\npolygon 18 (hole)        3 -1.68316e-04     -2.15e-13\npolygon 19 (hole)       36 -7.79904e+03     -9.97e-06\npolygon 20 (hole)        4 -2.05611e-02     -2.63e-11\npolygon 21 (hole)        3 -2.18000e-06     -2.79e-15\npolygon 22 (hole)        3 -3.65501e-03     -4.67e-12\npolygon 23 (hole)        3 -4.95057e-02     -6.33e-11\npolygon 24 (hole)        3 -3.99521e-02     -5.11e-11\npolygon 25 (hole)        3 -6.62377e-01     -8.47e-10\npolygon 26 (hole)        3 -2.09065e-03     -2.67e-12\npolygon 27              91  1.49663e+04      1.91e-05\npolygon 28 (hole)       26 -1.25665e+03     -1.61e-06\npolygon 29 (hole)      349 -1.21433e+03     -1.55e-06\npolygon 30 (hole)       20 -4.39069e+00     -5.62e-09\npolygon 31 (hole)       48 -1.38338e+02     -1.77e-07\npolygon 32 (hole)       28 -1.99862e+01     -2.56e-08\npolygon 33              40  1.38607e+04      1.77e-05\npolygon 34 (hole)       40 -6.00381e+03     -7.68e-06\npolygon 35 (hole)        7 -1.40545e-01     -1.80e-10\npolygon 36 (hole)       12 -8.36709e+01     -1.07e-07\npolygon 37              45  2.51218e+03      3.21e-06\npolygon 38             142  3.22293e+03      4.12e-06\npolygon 39             148  3.10395e+03      3.97e-06\npolygon 40              75  1.73526e+04      2.22e-05\npolygon 41              83  5.28920e+03      6.76e-06\npolygon 42             211  4.70521e+05      6.02e-04\npolygon 43             106  3.04104e+03      3.89e-06\npolygon 44             266  1.50631e+06      1.93e-03\npolygon 45              71  5.63061e+03      7.20e-06\npolygon 46              10  1.99717e+02      2.55e-07\npolygon 47             478  2.06120e+06      2.64e-03\npolygon 48             155  2.67502e+05      3.42e-04\npolygon 49            1027  1.27782e+06      1.63e-03\npolygon 50 (hole)        3 -1.16959e-03     -1.50e-12\npolygon 51              65  8.42861e+04      1.08e-04\npolygon 52              47  3.82087e+04      4.89e-05\npolygon 53               6  4.50259e+02      5.76e-07\npolygon 54             132  9.53357e+04      1.22e-04\npolygon 55 (hole)        3 -3.23310e-04     -4.13e-13\npolygon 56               4  2.69313e+02      3.44e-07\npolygon 57 (hole)        3 -1.46474e-03     -1.87e-12\npolygon 58            1045  4.44510e+06      5.68e-03\npolygon 59              22  6.74651e+03      8.63e-06\npolygon 60              64  3.43149e+04      4.39e-05\npolygon 61 (hole)        3 -1.98390e-03     -2.54e-12\npolygon 62 (hole)        4 -1.13774e-02     -1.46e-11\npolygon 63              14  5.86546e+03      7.50e-06\npolygon 64              95  5.96187e+04      7.62e-05\npolygon 65 (hole)        4 -1.86410e-02     -2.38e-11\npolygon 66 (hole)        3 -5.12482e-03     -6.55e-12\npolygon 67 (hole)        3 -1.96410e-03     -2.51e-12\npolygon 68 (hole)        3 -5.55856e-03     -7.11e-12\npolygon 69             234  2.08755e+06      2.67e-03\npolygon 70              10  4.90942e+02      6.28e-07\npolygon 71             234  4.72886e+05      6.05e-04\npolygon 72 (hole)       13 -3.91907e+02     -5.01e-07\npolygon 73              15  4.03300e+04      5.16e-05\npolygon 74             227  1.10308e+06      1.41e-03\npolygon 75              10  6.60195e+03      8.44e-06\npolygon 76              19  3.09221e+04      3.95e-05\npolygon 77             145  9.61782e+05      1.23e-03\npolygon 78              30  4.28933e+03      5.49e-06\npolygon 79              37  1.29481e+04      1.66e-05\npolygon 80               4  9.47108e+01      1.21e-07\nenclosing rectangle: [2667.54, 56396.44] x [15748.72, 50256.33] units\n                     (53730 x 34510 units)\nWindow area = 781945000 square units\nFraction of frame area: 0.422\n\n\n\n\n\n\n\n\n\nCombining PPP with OWIN"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#comparing-spatial-points-by-region",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#comparing-spatial-points-by-region",
    "title": "In-class Exercise 03",
    "section": "Comparing Spatial Points by Region",
    "text": "Comparing Spatial Points by Region\n\nExtracting region data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-data",
    "title": "In-Class Exercise 4: Spatial Weights and Applications",
    "section": "Loading Data",
    "text": "Loading Data\n\n\nReading layer `Hunan' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nReading layer `Hunan_2012' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\aspatial\\Hunan_2012.csv' \n  using driver `CSV'"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#combining-geospatial-and-aspatial-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#combining-geospatial-and-aspatial-data",
    "title": "In-Class Exercise 4: Spatial Weights and Applications",
    "section": "Combining Geospatial and Aspatial Data",
    "text": "Combining Geospatial and Aspatial Data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#using-gwmodel",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#using-gwmodel",
    "title": "In-Class Exercise 4: Spatial Weights and Applications",
    "section": "Using GWModel",
    "text": "Using GWModel\nSince it is an older library, they don’t accept sf, so we need to convert to sp"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-EHSA.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-EHSA.html",
    "title": "In-Class Exercise 5: Emerging Hot Spot Analysis: sfdep methods",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value 5. for each location with data, and with the hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05-EHSA.html#loading-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05-EHSA.html#loading-data",
    "title": "In-Class Exercise 5: Emerging Hot Spot Analysis: sfdep methods",
    "section": "Loading Data",
    "text": "Loading Data\n\n\nReading layer `Hunan' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "",
    "text": "We are using sfdep, not spdep"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#loading-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#loading-data",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Loading Data",
    "text": "Loading Data\n\n\nReading layer `Hunan' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nWe can track to see which columns are the same for both dataset"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#combining-data-using-left_join",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#combining-data-using-left_join",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Combining data using left_join",
    "text": "Combining data using left_join"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plot-coropleth",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plot-coropleth",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Plot Coropleth",
    "text": "Plot Coropleth"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#global-morans-i",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Global Moran’s I",
    "text": "Global Moran’s I\n\n\n$I\n[1] 0.30075\n\n$K\n[1] 7.640659\n\n\n\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#monte-carlo-global-morani-permutation-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#monte-carlo-global-morani-permutation-test",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Monte Carlo Global Moran’I Permutation test",
    "text": "Monte Carlo Global Moran’I Permutation test\nThis performs simulation, making it more reliable compared to the normal Moran’I test that only checks for one test data. nsim=99 will run the simulation 100 times as it uses 0 based indexing\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-morans-i",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Computing Local Moran’s I",
    "text": "Computing Local Moran’s I\n\n\nSimple feature collection with 88 features and 21 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 22\n         ii        eii     var_ii    z_ii    p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.00147  0.00177   0.000418   -0.158  0.874       0.82         0.41   -0.812\n 2  0.0259   0.00641   0.0105      0.190  0.849       0.96         0.48   -1.09 \n 3 -0.0120  -0.0374    0.102       0.0796 0.937       0.76         0.38    0.824\n 4  0.00102 -0.0000349 0.00000437  0.506  0.613       0.64         0.32    1.04 \n 5  0.0148  -0.00340   0.00165     0.449  0.654       0.5          0.25    1.64 \n 6 -0.0388  -0.00339   0.00545    -0.480  0.631       0.82         0.41    0.614\n 7  3.37    -0.198     1.41        3.00   0.00266     0.08         0.04    1.46 \n 8  1.56    -0.265     0.804       2.04   0.0417      0.08         0.04    0.459\n 9  4.42     0.0450    1.79        3.27   0.00108     0.02         0.01    0.746\n10 -0.399   -0.0505    0.0859     -1.19   0.234       0.28         0.14   -0.685\n# ℹ 78 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, NAME_2 &lt;chr&gt;, ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;,\n#   ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;, Year &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\nVisualizing Local Moran’s I\n\n\n\n\n\n\n\nVisualizing p-value of Local Moran’s I\n\n\n\n\n\n\n\nVisualizing LISA Map"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-gi-statistics",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-local-gi-statistics",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Computing Local Gi* Statistics",
    "text": "Computing Local Gi* Statistics\n\n\nSimple feature collection with 88 features and 17 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 18\n   gi_star   e_gi    var_gi p_value   p_sim p_folded_sim skewness kurtosis nb   \n     &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;nb&gt; \n 1  0.0416 0.0114   6.41e-6  0.0493 9.61e-1         0.7      0.35    0.875 &lt;int&gt;\n 2 -0.333  0.0106   3.84e-6 -0.0941 9.25e-1         1        0.5     0.661 &lt;int&gt;\n 3  0.281  0.0126   7.51e-6 -0.151  8.80e-1         0.9      0.45    0.640 &lt;int&gt;\n 4  0.411  0.0118   9.22e-6  0.264  7.92e-1         0.6      0.3     0.853 &lt;int&gt;\n 5  0.387  0.0115   9.56e-6  0.339  7.34e-1         0.62     0.31    1.07  &lt;int&gt;\n 6 -0.368  0.0118   5.91e-6 -0.583  5.60e-1         0.72     0.36    0.594 &lt;int&gt;\n 7  3.56   0.0151   7.31e-6  2.61   9.01e-3         0.06     0.03    1.09  &lt;int&gt;\n 8  2.52   0.0136   6.14e-6  1.49   1.35e-1         0.2      0.1     1.12  &lt;int&gt;\n 9  4.56   0.0144   5.84e-6  3.53   4.17e-4         0.04     0.02    1.23  &lt;int&gt;\n10  1.16   0.0104   3.70e-6  1.82   6.86e-2         0.12     0.06    0.416 &lt;int&gt;\n# ℹ 78 more rows\n# ℹ 9 more variables: wts &lt;list&gt;, NAME_2 &lt;chr&gt;, ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;,\n#   ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;, Year &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-gi",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-gi",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Visualizing Gi*",
    "text": "Visualizing Gi*"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-p-value-of-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-p-value-of-hcsa",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Visualizing p-value of HCSA",
    "text": "Visualizing p-value of HCSA"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-local-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-local-hcsa",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Visualizing Local HCSA",
    "text": "Visualizing Local HCSA"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-hot-spot-and-cold-spot-areas",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-hot-spot-and-cold-spot-areas",
    "title": "In-Class Exercise 5: Global and Local Measuers of Spatial Autocorrelation - sfdep methods",
    "section": "Visualizing Hot Spot and Cold Spot Areas",
    "text": "Visualizing Hot Spot and Cold Spot Areas"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely: - hierarchical cluster analysis; and - spatially constrained cluster analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#importing-geospatial-data",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\nWe will use st_read to save the geospatial data to a variable called shan_sf, and use summary() to get a feel of the dataset"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#importing-aspatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#importing-aspatial-data",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Importing Aspatial Data",
    "text": "Importing Aspatial Data\nFor the aspatial data, we will use read_csv()\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#eda",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#eda",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "EDA",
    "text": "EDA\n\nHistogram\nHistogram is useful to know the distribution of the data.\nHere, we will see the distribution of the original RADIO\nAnd here we will see the distribution of the derived RADIO_PR\nHere is all the histograms for the derived variables\n\n\nBoxplot\nBoxplot is useful to detect outliers\nWe can look at the RADIO variable\nHere we are looking at the derived RADIO_PR\n\n\nChoropleth\n\nJoining geospatial and aspatial data\nBefore we can make a choropleth map, we need to combine the geospatial and aspatial data. We can use left_join() to do so, based on the TS_PCODE column\nThe combined data is saved into an rds file, which we can call with read_rds()\n\n\nPreparing choropleth\nWe can use qtm() to quickly make a choropleth\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map)\nNotice that the choropleth maps above clearly show that townships with relatively larger number ot households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate by using the code chunk below."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#extracting-cluster-analysis",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#extracting-cluster-analysis",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "1. Extracting Cluster Analysis",
    "text": "1. Extracting Cluster Analysis\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\nThe final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nWe need to change the rows by township name instead of row number, so that we can call the rows by the township name"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#data-standardisation",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#data-standardisation",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2. Data Standardisation",
    "text": "2. Data Standardisation\n\nMin-Max Standardisation\nnormalize() uses min-max method to standardize the data. The min-max standardized variables will then turn to be between 0-1\n\n\nZ-Score Standardisation\nscale() will standardizes data using Z-score methods. The mean and standard deviation of the Z-score standardized variables will be 0 and 1 respectively. Z-score standardisation should only be used if we are sure that the data is normally distributed\n\n\nVisualising Standardised Clustering Variables\nIt is good practice to visualise the distribution.\nWith histogram:\nWith density plot:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#computing-proximity-matrix",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#computing-proximity-matrix",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3. Computing Proximity Matrix",
    "text": "3. Computing Proximity Matrix\nWe will use dist() from R to compute the proximity matrix. dist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#computing-hieararchical-clustering",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#computing-hieararchical-clustering",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4. Computing Hieararchical Clustering",
    "text": "4. Computing Hieararchical Clustering\nWe will use hclust() to compute hieararchical clustering function. hclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#gap-statistic-method",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#gap-statistic-method",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Gap Statistic Method",
    "text": "Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.We can use clusGap() from the cluster package\nthe hcut function used inside is taken from factoextra. Also from factoextra, we can use fvis_gap_stat() to visualize the plot\nBased on the plot, the recommended number of cluster is 1 (highest Gap statistic)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#transform-data-to-matrix",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#transform-data-to-matrix",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Transform Data to Matrix",
    "text": "Transform Data to Matrix\nTo make our heatmap, we need to convert the data into a matrix"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#plotting-with-heatmaply",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#plotting-with-heatmaply",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Plotting With heatmaply()",
    "text": "Plotting With heatmaply()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#compute-neighbour-list",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#compute-neighbour-list",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "1. Compute Neighbour List",
    "text": "1. Compute Neighbour List\nWe will use poly2nd() to compute neighbours list"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#computing-minimum-spanning-tree",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#computing-minimum-spanning-tree",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2. Computing Minimum Spanning Tree",
    "text": "2. Computing Minimum Spanning Tree\nFirst, we calculate the cost of each edge with nbcosts()\nNext, we incorporate these costs into a weights object with nb2listw(). We set style as B to make sure the cost values are not row-standardised\nBased on the weights, the spanning tree is computed by mstree()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#comparing-spatially-constrained-clusters-with-skater-method",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#comparing-spatially-constrained-clusters-with-skater-method",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3. Comparing Spatially Constrained Clusters With SKATER Method",
    "text": "3. Comparing Spatially Constrained Clusters With SKATER Method\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters. The result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\nWe can check the cluster assignment\nAnd find out how many observations are in each cluster"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#visualising-the-clusters-in-choropleth-map",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#visualising-the-clusters-in-choropleth-map",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "5. Visualising The CLusters In Choropleth Map",
    "text": "5. Visualising The CLusters In Choropleth Map\nFor easy comparison:"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Ward-like Hierarchical Clustering: ClustGeo",
    "text": "Ward-like Hierarchical Clustering: ClustGeo\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#mapping-the-formed-clusters-1",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#mapping-the-formed-clusters-1",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Mapping The Formed Clusters",
    "text": "Mapping The Formed Clusters"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#individual-clustering-variable",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#individual-clustering-variable",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Individual Clustering Variable",
    "text": "Individual Clustering Variable\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#multivariate",
    "href": "In-class_Ex/In-class_Ex06/In-Class_Ex06.html#multivariate",
    "title": "In-Class Exercise 6: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Multivariate",
    "text": "Multivariate\nWe can use parallel coordinate plot to reveal clustering variables. We will use ggparcoord() from Gally\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nWe can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.In the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#geospatial-data",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#geospatial-data",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Geospatial Data",
    "text": "Geospatial Data\nWe will use the MP14_SUBZONE_WEB_PL for the geospatial data.\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nDon’t forget to check the crs and update it if needed\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#aspatial-data",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#aspatial-data",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Aspatial Data",
    "text": "Aspatial Data\nWe can use read_csv() to read the csv file for the aspatial data\n\n\n# A tibble: 6 × 23\n  LATITUDE LONGITUDE POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD\n     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     1.29      104.   118635       3000000      309    30     7.94\n2     1.33      104.   288420       3880000      290    32     6.61\n3     1.31      104.   267833       3325000      248    33     6.90\n4     1.31      104.   258380       4250000      127     7     4.04\n5     1.32      104.   467169       1400000      145    28    11.8 \n6     1.31      104.   466472       1320000      139    22    10.3 \n# ℹ 16 more variables: PROX_CHILDCARE &lt;dbl&gt;, PROX_ELDERLYCARE &lt;dbl&gt;,\n#   PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;\n\n\nWe will convert the tibble data to a sf using st_as_sf() abd transform the crs from 4326, since the geometry comes from lat and long, to 3414 for Singapore’s crs\n\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#eda-using-statistical-graphics",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#eda-using-statistical-graphics",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "EDA using statistical graphics",
    "text": "EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\n\n\n\n\nThe distribution is right-skewed. Statistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#multiple-histogram-plots-distribution-of-variables",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#multiple-histogram-plots-distribution-of-variables",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Multiple Histogram Plots distribution of variables",
    "text": "Multiple Histogram Plots distribution of variables\nWe will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#drawing-statistical-point-map",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#drawing-statistical-point-map",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Drawing Statistical Point Map",
    "text": "Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\n\n\n\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#simple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#simple-linear-regression-method",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Simple Linear Regression Method",
    "text": "Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n  *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#multiple-linear-regression-method",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Multiple Linear Regression Method",
    "text": "Multiple Linear Regression Method\n\nVisualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\n\n\n\n\nWe can also use ggcorrmat() from ggstatsplot to make the correlation matrix\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\nBuilding a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#preparing-publication-quality-table-olsrr-method",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#preparing-publication-quality-table-olsrr-method",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Preparing Publication Quality Table: olsrr method",
    "text": "Preparing Publication Quality Table: olsrr method\nWe will revise the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below\n\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#preparing-publication-quality-table-gtsummary-method",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#preparing-publication-quality-table-gtsummary-method",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Preparing Publication Quality Table: gtsummary method",
    "text": "Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression repor\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\nVisualising model parameters\n\n\n\n\n\n\n\n\n\n\n\n\nChecking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\nTest for non-linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for normality assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\nTest for spatial autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\nNext, we will join the newly created data frame with condo_resale.sf object.\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\n\n\n\n\n\n\nswitch back to “plot” mode before continue.\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 2.2e-16 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#building-fixed-bandwidth-gwr-model",
    "href": "In-class_Ex/In-class_Ex07/In-Class_Ex07.html#building-fixed-bandwidth-gwr-model",
    "title": "In-Class Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Building Fixed Bandwidth GWR Model",
    "text": "Building Fixed Bandwidth GWR Model\n\nComputing fixed bandwidth\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres\n\nGWModel method - fixed bandwidth\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-25 03:42:45.064156 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-03-25 03:42:45.701512 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1.\n\n\n\nBuilding Adaptive Bandwidth GWR Model\n\nComputing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\nConstructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\nThe code below can be used to display the model output.\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-25 03:42:50.60761 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-03-25 03:42:51.799344 \n\n\n\n\n\nVisualizing GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list.\n\n\nConverting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\n\n\nVisualizing local R2\nThe code chunks below is used to create an interactive point symbol map.\n\n\n\n\n\n\n\n\n\nVisualizing coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy URA Planning Region"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class Exercise 9: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#revising-mlr-model",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#revising-mlr-model",
    "title": "In-class Exercise 9: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Revising mlr model",
    "text": "Revising mlr model\n\n\nn= 7950 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n 1) root 7950 1.139546e+14 433705.6  \n   2) PROX_CBD&gt;=7.974483 6665 4.472144e+13 403736.0  \n     4) REMAINING_LEASE_MTHS&lt; 1020.5 4228 1.573100e+13 370187.4  \n       8) PROX_GOOD_PRISCH&gt;=3.629405 2271 3.851141e+12 340796.1 *\n       9) PROX_GOOD_PRISCH&lt; 3.629405 1957 7.641480e+12 404294.6 *\n     5) REMAINING_LEASE_MTHS&gt;=1020.5 2437 1.597594e+13 461940.1  \n      10) PROX_CBD&gt;=10.40657 2331 9.762718e+12 451754.4  \n        20) PROX_GOOD_PRISCH&gt;=4.866983 1123 2.801796e+12 423493.8 *\n        21) PROX_GOOD_PRISCH&lt; 4.866983 1208 5.230246e+12 478026.4 *\n      11) PROX_CBD&lt; 10.40657 106 6.532500e+11 685929.1 *\n   3) PROX_CBD&lt; 7.974483 1285 3.219685e+13 589151.4  \n     6) REMAINING_LEASE_MTHS&lt; 930.5 745 6.613365e+12 486637.6  \n      12) FLOOR_AREA_SQM&lt; 98.5 451 2.446537e+12 442460.5 *\n      13) FLOOR_AREA_SQM&gt;=98.5 294 1.936449e+12 554405.7 *\n     7) REMAINING_LEASE_MTHS&gt;=930.5 540 6.952722e+12 730582.5  \n      14) REMAINING_LEASE_MTHS&lt; 1071.5 314 2.461969e+12 676641.3 *\n      15) REMAINING_LEASE_MTHS&gt;=1071.5 226 2.307737e+12 805527.4 *\n\n\n\n\n\n\n\n\n\nRanger result\n\nCall:\n ranger(RESALE_PRICE ~ ., train_df, importance = \"impurity\") \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      7950 \nNumber of independent variables:  15 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       738005688 \nR squared (OOB):                  0.9485198 \n\n\n\n\n\n\n\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard      61617."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications\nThis is the course website of IS415 I study this term. You will find my course work on this website.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/data/Geospatial/MPSZ-2019/MPSZ-2019.html",
    "href": "Take-home_Ex/Take-home_Ex01/data/Geospatial/MPSZ-2019/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "",
    "text": "#1. Overview"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background-human-mobility-the-movement-of-human-beings-in-space-and-time-reflects-the-spatial-temporal-characteristics-of-human-behavior.-with-the-advancement-information-and-communication-technologies-ict-especially-smart-phone-a-large-volume-of-data-related-to-human-mobility-have-been-collected.-by-using-appropriate-gis-analysis-methods-these-data-are-potentially-useful-in-supporting-smart-city-planning-and-management.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background-human-mobility-the-movement-of-human-beings-in-space-and-time-reflects-the-spatial-temporal-characteristics-of-human-behavior.-with-the-advancement-information-and-communication-technologies-ict-especially-smart-phone-a-large-volume-of-data-related-to-human-mobility-have-been-collected.-by-using-appropriate-gis-analysis-methods-these-data-are-potentially-useful-in-supporting-smart-city-planning-and-management.",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "1.1 Background Human mobility, the movement of human beings in space and time, reflects the spatial-temporal characteristics of human behavior. With the advancement Information and Communication Technologies (ICT) especially smart phone, a large volume of data related to human mobility have been collected. By using appropriate GIS analysis methods, these data are potentially useful in supporting smart city planning and management.",
    "text": "1.1 Background Human mobility, the movement of human beings in space and time, reflects the spatial-temporal characteristics of human behavior. With the advancement Information and Communication Technologies (ICT) especially smart phone, a large volume of data related to human mobility have been collected. By using appropriate GIS analysis methods, these data are potentially useful in supporting smart city planning and management.\nIn Singapore, one of the important source of data related to human mobility is from Land Transport Authority (LTA) DataMall. Two data sets related to human mobility are provided by the portal, they are: Passenger Volume by Origin Destination Train Stations and Passenger Volume by Origin Destination Bus Stops. One of the limitation of these data sets is that their location are biased to either bus stops or MRT/LRT stations. In 2020, another very interesting human mobility data set called Grab Posisi was released by GRAB, one of the largest shared taxi operator in South-east Asia. There are two data sets been released and one of them is for Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate spatial point patterns analysis methods to discover the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#tasks",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#tasks",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "1.3 Tasks",
    "text": "1.3 Tasks\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer in sf tibble data.frames:\n\nGrab taxi location points either by origins or destinations.\nRoad layer within Singapore excluding outer islands.\nSingapore boundary layer excluding outer islands\n\nUsing the extracted data, derive traditional Kernel Density Estimation layers.\nUsing the extracted data, derive either Network Kernel Density Estimation (NKDE) or Temporal Network Kernel Density Estimation (TNKDE)\nUsing appropriate tmap functions, display the kernel density layers on openstreetmap of Singapore.\nDescribe the spatial patterns revealed by the kernel density maps."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-datasets",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.1 Loading datasets",
    "text": "3.1 Loading datasets\n\n3.1.1 Grab-Posisi\nWe can load all the Grab-Posisi datasets with this code chunk:\n\nfile_list &lt;- list.files('./data/GrabPosisi')\n\ncombined &lt;- list()\nfor(i in seq(file_list)) {\n  data_name &lt;- paste0('grabposisi', i - 1)\n  temp &lt;- read_parquet(paste0('data/GrabPosisi/', file_list[i]))\n  combined[[i]] &lt;- temp\n}\n\ngrabposisi &lt;- bind_rows(combined)\n\nWhat the code chunk above does, is that it takes in the names of the files in the specified folder, turning it into a list.\nNow, we explore the grabposisi data\n\nglimpse(grabposisi)\n\nRows: 30,329,685\nColumns: 9\n$ trj_id        &lt;chr&gt; \"70014\", \"73573\", \"75567\", \"1410\", \"4354\", \"32630\", \"646…\n$ driving_mode  &lt;chr&gt; \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", \"car\", …\n$ osname        &lt;chr&gt; \"android\", \"android\", \"android\", \"android\", \"android\", \"…\n$ pingtimestamp &lt;int&gt; 1554943236, 1555582623, 1555141026, 1555731693, 15555844…\n$ rawlat        &lt;dbl&gt; 1.342326, 1.321781, 1.327088, 1.262482, 1.283799, 1.3003…\n$ rawlng        &lt;dbl&gt; 103.8890, 103.8564, 103.8613, 103.8238, 103.8072, 103.90…\n$ speed         &lt;dbl&gt; 18.910000, 17.719076, 14.021548, 13.026521, 14.812943, 2…\n$ bearing       &lt;int&gt; 248, 44, 34, 181, 93, 73, 82, 321, 324, 31, 203, 50, 252…\n$ accuracy      &lt;dbl&gt; 3.900, 4.000, 3.900, 4.000, 3.900, 3.900, 3.000, 3.649, …\n\n\nWe noticed that pingtimestamp is an integer field, so we need to convert pingtimestamp field to a datetime format (POCIXCT)\n\ngrabposisi$pingtimestamp &lt;- as_datetime(grabposisi$pingtimestamp)\n\n\n3.1.1.1 Origin\nNow, we can extract the origin of a ride, based on trajectory id. We will group the rows based on trajectory id, and sort it in ascending order based on the timestamp. The first index of every trajectory id will be the starting point of that ride. After the extraction, we can use use st_as_sf() to convert it into an sf, with the parameter crs=4326 as the dataset is taken from GPS data, which typically uses the WGS-84. However, we need to use st_transform to set the crs to 3414, which is used in Singapore.\n\nsetDT(grabposisi)\n\ngrabposisi[, `:=`(\n  weekday = wday(pingtimestamp),\n  starting_hour = factor(hour(pingtimestamp)),\n  day = factor(mday(pingtimestamp))\n)]\n\norigin &lt;- grabposisi[order(trj_id, pingtimestamp)\n  ][, .SD[1], by = .(trj_id)\n  ] |&gt; st_as_sf(coords=c(\"rawlng\", \"rawlat\"), crs=4326) |&gt; st_transform(3414)\n\nst_crs(origin)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nLet’s filter so that we only have cars in the data\n\norigin &lt;- filter(origin, driving_mode == 'car')\n\nNow, we can see what it looks like\n\nqtm(origin)\n\n\n\n\n\n\n3.1.1.2 Destination\nWe can apply a similar logic to get the destination. The difference is that we need to sort it in descending order based on the timestamp.\n\nsetDT(grabposisi)\n\ngrabposisi[, `:=`(\n  weekday = wday(pingtimestamp),\n  starting_hour = factor(hour(pingtimestamp)),\n  day = factor(mday(pingtimestamp))\n)]\n\ndestination &lt;- grabposisi[order(trj_id, -pingtimestamp)\n  ][, .SD[1], by = .(trj_id)\n  ] |&gt; st_as_sf(coords=c(\"rawlng\", \"rawlat\"), crs=4326) |&gt; st_transform(3414)\n\nst_crs(destination)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nSame as above, we can filter it\n\ndestination &lt;- filter(destination, driving_mode == 'car')\n\nAnd plot it\n\nqtm(destination)\n\n\n\n\n\n\n\n3.1.2 Geospatial Data\n\n3.1.2.1 MPSZ\nNow, we need to load the geospatial data. Let’s start with the 2019 Subzone Master Plan\n\nmpsz2019_sf &lt;- st_read(dsn='data/Geospatial/MPSZ-2019', layer='MPSZ-2019') |&gt; st_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\Geospatial\\MPSZ-2019' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nst_crs(mpsz2019_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nAnd see what it looks like on a plot.\n\nqtm(mpsz2019_sf)\n\n\n\n\nNotice that this includes the surrounding islands. To extract only the main island, we can filter out the surrounding islands with this code chunk below. The !grepl() function will find any of the rows that doesn’t include “ISLAND” in their PLN_AREA_N column. You can see the difference between the plots\nNotice that this includes the surrounding islands. To extract only the main island, we can filter out the surrounding islands with this code chunk below\n\nmpsz2019_sf &lt;- mpsz2019_sf[!grepl(\"ISLAND\", mpsz2019_sf$PLN_AREA_N, ignore.case = TRUE), ]\nqtm(mpsz2019_sf)\n\n\n\n\nNow, we can get the outline of Singapore’s main island with st_union()\n\nsg_sf &lt;- mpsz2019_sf |&gt; st_union()\nplot(sg_sf)\n\n\n\n\n\n\n3.1.2.2 Road Data\nAfter the Master Plan, we can move on to the Road Data Set\n\nroad_sf &lt;- st_read(dsn = 'data/Geospatial/malaysia-singapore-brunei-latest-free.shp', layer='gis_osm_roads_free_1') |&gt; st_transform(crs=3414)\n\nReading layer `gis_osm_roads_free_1' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\Geospatial\\malaysia-singapore-brunei-latest-free.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1765176 features and 10 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 99.66041 ymin: 0.8021131 xmax: 119.2601 ymax: 7.514393\nGeodetic CRS:  WGS 84\n\nst_crs(road_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nglimpse(road_sf)\n\nRows: 1,765,176\nColumns: 11\n$ osm_id   &lt;chr&gt; \"4386520\", \"4578273\", \"4579495\", \"4579533\", \"4579534\", \"45795…\n$ code     &lt;int&gt; 5113, 5114, 5122, 5122, 5122, 5122, 5141, 5122, 5122, 5122, 5…\n$ fclass   &lt;chr&gt; \"primary\", \"secondary\", \"residential\", \"residential\", \"reside…\n$ name     &lt;chr&gt; \"Orchard Road\", \"Jalan Bukit Bintang\", \"Jalan Nagasari\", \"Per…\n$ ref      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ oneway   &lt;chr&gt; \"F\", \"F\", \"B\", \"B\", \"B\", \"F\", \"F\", \"F\", \"F\", \"F\", \"B\", \"B\", \"…\n$ maxspeed &lt;int&gt; 50, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 0, 0,…\n$ layer    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ bridge   &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"…\n$ tunnel   &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"T\", \"F\", \"F\", \"F\", \"F\", \"F\", \"…\n$ geometry &lt;LINESTRING [m]&gt; LINESTRING (27637.52 32038...., LINESTRING (-20666…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-to-ppp",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-to-ppp",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.2 Converting to PPP",
    "text": "3.2 Converting to PPP\nSince KDE requires the point data to be in ppp format, we will convert our origin and destination to ppp. To do this, we can convert it into a Spatial* object with as_Spatial(), then to an sp object with as(x, ‘SpatialPoints’), then finally to ppp with as(x, ‘ppp’)\n\norigin_spatial &lt;- as_Spatial(origin)\norigin_sp &lt;- as(origin_spatial, 'SpatialPoints')\norigin_ppp &lt;- as(origin_sp, 'ppp')\n\ndestination_spatial &lt;- as_Spatial(destination)\ndestination_sp &lt;- as(destination_spatial, 'SpatialPoints')\ndestination_ppp &lt;- as(destination_sp, 'ppp')\n\n#Alternatively, we can also use the commented codes below to directly convert to ppp\n# origin_ppp &lt;- as.ppp(origin)\n# destination_ppp &lt;- as.ppp(destination)\n\nPlot it to see how it looks like\n\nplot(origin_ppp)\n\n\n\nplot(destination_ppp)\n\n\n\n\nWe can check for duplicates\n\nany(duplicated(origin_ppp))\n\n[1] FALSE\n\nany(duplicated(destination_ppp))\n\n[1] FALSE\n\n\nSince both origin_ppp and destination_ppp doesn’t have duplicates, we can move on to the next step"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-to-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-to-owin-object",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.3 Converting to OWIN Object",
    "text": "3.3 Converting to OWIN Object\nWe need to convert our sg_sf, which is the Singapore main island’s outline, to an OWIN object\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combining-point-events-object-and-owin-object",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "3.5 Combining point events object and OWIN object",
    "text": "3.5 Combining point events object and OWIN object\nBefore performing the analysis, we need to extract only points that are inside Singapore’s main island\n\norigin_sg &lt;- origin_ppp[sg_owin]\ndestination_sg &lt;- destination_ppp[sg_owin]\n\nConvert it to use kilometres as units, since what we have now is in terms of metres\n\norigin_sg_km &lt;- rescale(origin_sg, 1000, 'km')\ndestination_sg_km &lt;- rescale(destination_sg, 1000, 'km')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.1 First Order Spatial Point Patterns Analysis",
    "text": "4.1 First Order Spatial Point Patterns Analysis\n\n4.1.1 KDE with automatic bandwith selection method\nWe will compare computations using these method: - bw.diggle() - bw.CvL() - bw.scott() - bw.ppl()\n\nOrigin\n\nkde_origin_diggle &lt;- density(origin_sg_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_origin_cvl &lt;- density(origin_sg_km,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\n\nkde_origin_scott &lt;- density(origin_sg_km,\n                              sigma=bw.scott,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\n\nkde_origin_ppl &lt;- density(origin_sg_km,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nNow we can see the plot for comparison\n\npar(mfrow=c(2,2))\nplot(kde_origin_diggle, main = \"bw.diggle\")\nplot(kde_origin_cvl, main = \"bw.cvl\")\nplot(kde_origin_scott, main = \"bw.scott\")\nplot(kde_origin_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\nDestination\n\nkde_destination_diggle &lt;- density(destination_sg_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_destination_cvl &lt;- density(destination_sg_km,\n                              sigma=bw.CvL,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_destination_scott &lt;- density(destination_sg_km,\n                              sigma=bw.scott,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nkde_destination_ppl &lt;- density(destination_sg_km,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nNow we can see the plot for comparison\n\npar(mfrow=c(2,2))\nplot(kde_destination_diggle, main = \"bw.diggle\")\nplot(kde_destination_cvl, main = \"bw.cvl\")\nplot(kde_destination_scott, main = \"bw.scott\")\nplot(kde_destination_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n4.1.2 Adaptive Bandwidth KDE\nThe issue about fixed bandwidth is that less crowded areas, such as countrysides, tends to be less dense compared to more crowded areas like CBDs or city centres. Thus, we can use the adaptive.density() to help overcome this.\n\nkde_origin_adaptive &lt;- adaptive.density(origin_sg_km, method=\"kernel\")\n\nkde_destination_adaptive &lt;- adaptive.density(destination_sg_km, method=\"kernel\")\n\nWe can see the KDE through these plots\n\nplot(kde_origin_adaptive)\n\n\n\n\n\nplot(kde_destination_adaptive)\n\n\n\n\n\n\n4.1.3 Converting KDE Output to Grid Object\nWe can convert the output into a grid object for a more suitable mapping without changing the result\n\ngrid_kde_origin &lt;- as.SpatialGridDataFrame.im(kde_origin_adaptive)\nspplot(grid_kde_origin)\n\n\n\n\n\ngrid_kde_destination &lt;- as.SpatialGridDataFrame.im(kde_destination_adaptive)\nspplot(grid_kde_destination)\n\n\n\n\n\n\n4.1.4 Converting Grid to Raster\nNext, we will conver the grid to a RasterLayer object using the raster() function\n\nkde_origin_raster &lt;- raster(kde_origin_adaptive)\nkde_origin_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.254928e-14, 2296.831  (min, max)\n\nkde_destination_raster &lt;- raster(kde_destination_adaptive)\nkde_destination_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -1.882384e-13, 1996.507  (min, max)\n\n\nSince there is no crs property when we first make a RasterLayer object, we can assign it\n\nprojection(kde_origin_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_origin_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.254928e-14, 2296.831  (min, max)\n\nprojection(kde_destination_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_destination_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4162063, 0.2250614  (x, y)\nextent     : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -1.882384e-13, 1996.507  (min, max)\n\n\n\n\n4.1.5 Visualization\n\ntm_shape(kde_origin_raster) + \n  tm_raster(\"layer\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\ntm_shape(kde_destination_raster) + \n  tm_raster(\"layer\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n4.1.6 Testing Spatial Point Patterns Using Clark and Evans Test\n\nOrigin\nThe test hypotheses are:\nHo = The distribution of grab origin points are randomly distributed.\nH1= The distribution of grab origin points are not randomly distributed.\nThe 95% confident interval will be used.\nWe can use the CLark-Evans test of aggregation using clarkevans.test() from statspat\n\norigin_clarkevans &lt;- clarkevans.test(origin_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\norigin_clarkevans\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  origin_ppp\nR = 0.21648, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe Clark-Evans test shows an R value that is much smaller than 1. This means that the points are very close to each other, implying that the points are clustered. The p-value also shows that we can reject the null hyphotesis that the distribution of grab origin points are randomly distributed\n\n\nDestination\nThe test hypotheses are:\nHo = The distribution of grab destination points are randomly distributed.\nH1= The distribution of grab destination points are not randomly distributed.\nThe 95% confident interval will be used.\n\ndestination_clarkevans &lt;- clarkevans.test(destination_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\ndestination_clarkevans\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  destination_ppp\nR = 0.23392, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe Clark-Evans test shows an R value that is much smaller than 1. This means that the points are very close to each other, implying that the points are clustered. The p-value also shows that we can reject the null hyphotesis that the distribution of grab destination points are randomly distributed"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-spatial-point-pattern-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-spatial-point-pattern-analysis",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "4.2 Network Constrained Spatial Point Pattern Analysis",
    "text": "4.2 Network Constrained Spatial Point Pattern Analysis\nFor Network Constrained Spatial Point Pattern Analysis, we are taking into account the roads in Singapore.\n\n4.2.1 Preparing Road Objects\nFirst, we prepare an object that contains roads in Singapore. We can use st_within to extract the roads from our dataset from OSM that matches/intersects with the MPSZ. Since we are only looking at roads that is suitable for cars, one way we can do it is by excluding rows where the max speed is 0\n\nsg_road &lt;- road_sf[st_contains(sg_sf, road_sf, sparse = FALSE), ] |&gt; filter(maxspeed &gt; 0)\nqtm(sg_road)\n\n\n\n\n\n\n4.2.2 NKDE for Origin\nFirst, let’s see how it looks like\n\ntm_shape(sg_road) + tm_lines() +\n  tm_shape(origin) + tm_dots('red', size=0.02)\n\n\n\n\n\n4.2.2.1 Preparing Origin Lixels and Line Centre Points\nWe will also extract the origin to include only those who are inside the Singapore main island’s boundary\n\norigin_events &lt;- origin[st_contains(sg_sf, origin, sparse = FALSE), ]\norigin_events &lt;- data.frame(origin_events$trj_id, origin_events$geometry) |&gt; st_as_sf(crs=3414)\nst_crs(origin_events)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nBefore performing NKDE, we need to cut the sg_road into lixels. In this example, our lixels will have a length of 700 and minimum length of 350\n\norigin_lixels &lt;- lixelize_lines(sg_road, \n                         700, \n                         mindist = 350)\n\n\norigin_samples &lt;- lines_center(origin_lixels)\n\n\n\n4.2.2.2 Performing NKDE\nWe will be using nkde.mc(), instead of the usual nkde(). The difference between the two functions is that when paired with the future package, nkde.mc allows for multiple workers to compute the nkde at the same time. We will also set the agg value to 20, which means that points within 20 metres of each other will be aggregrated. The grid_shape will also be set to c(16, 16) to indicate that we are splitting the data to a 16x16 grid that will be computated separately and combined together in the end. All these steps will help in making the runtime of the code a bit faster compared to using the usual default setup.\n\nfuture::plan(future::multisession(workers=4))\n\n\norigin_densities &lt;- nkde.mc(sg_road, \n                      events = origin_events,\n                      w = rep(1,nrow(origin_events)),\n                      samples = origin_samples,\n                      kernel_name = \"quartic\",\n                      bw = 300,\n                      adaptive = TRUE, # we use here an adaptive bandwidth\n                      trim_bw = 600, # the maximum local values of bandwidth will be 600m\n                      div= \"bw\",\n                      method = \"simple\", \n                      digits = 1, \n                      tol = 1,\n                      grid_shape = c(16,16), \n                      max_depth = 8,\n                      agg = 20,\n                      sparse = TRUE,\n                      verbose = FALSE)\n\nif (!inherits(future::plan(), \"sequential\")) future::plan(future::sequential)\n\n\n\n4.2.2.3 Insert Densities to Lixel and Sample\nAfter finishing the computation, we need to put the density value into the samples and lixels. Don’t forget to adjust the scale to kilometer\n\norigin_samples$density &lt;- origin_densities$k\norigin_lixels$density &lt;- origin_densities$k\n\norigin_samples$density &lt;- origin_samples$density*1000\norigin_lixels$density &lt;- origin_lixels$density*1000\n\n\n\n4.2.2.4 Visualization\nWe can use tmaps to visualize the result of our NKDE\n\ntm_shape(origin_lixels)+\n  tm_lines()+\ntm_shape(origin_samples)+\n  tm_dots(\"density\", style=\"kmeans\", palette=\"GnBu\", n=7, size=0.2)\n\n\n\n\n4.2.3 NKDE for Destination\nFor destination, we are doing the exact same process, but changing the event points to the destination points. To get the NKDE for Destination points, simply use the code for the Origin points, but change the dataset to the Destination dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#defining-a-kernel-density-map-function",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#defining-a-kernel-density-map-function",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "5.1 Defining a Kernel Density Map Function",
    "text": "5.1 Defining a Kernel Density Map Function\nFirst, we can create a function called density_map, which can be called later on to visualize our maps.\n\ndensity_map &lt;- function(raster_object, map_title) {\n  tm_basemap(\"OpenStreetMap\") +\ntm_shape(raster_object) +\n  tm_raster(\"layer\", alpha=0.65) + \n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            legend.height = 0.5, \n            legend.width = 0.4,\n            main.title = map_title,\n            main.title.position = 'center',\n            main.title.size = 1,\n            frame = FALSE)\n  }"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-density-map",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-density-map",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "5.2 Plotting Density Map",
    "text": "5.2 Plotting Density Map\nTo plot our density map, we can coll on the density_map function we defined before\n\norigin_density_map &lt;- density_map(kde_origin_raster, \"GrabPosisi Origin\")\norigin_density_map\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\ndestination_density_map &lt;- density_map(kde_destination_raster, \"GrabPosisi Destination\")\ndestination_density_map\n\nVariable(s) \"layer\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#saving-data-to-rds",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#saving-data-to-rds",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Saving data to RDS",
    "text": "Saving data to RDS\nWe can use write_rds() to save our loaded data into an RDS file, making it easier to reload any data we might need again\n\nwrite_rds(origin, 'data/rds/origin.rds')\nwrite_rds(destination, 'data/rds/destination.rds')\nwrite_rds(road_sf, 'data/rds/road_sf.rds')\nwrite_rds(mpsz2019_sf, 'data/rds/mpsz2019_sf.rds')\nwrite_rds(origin_lixels, 'data/rds/origin_lixels.rds')\nwrite_rds(destination_lixels, 'data/rds/destination_lixels.rds')\nwrite_rds(origin_samples, 'data/rds/origin_samples.rds')\nwrite_rds(destination_samples, 'data/rds/destination_samples.rds')\nwrite_rds(sg_road, 'data/rds/sg_road.rds')\nwrite_rds(origin_densities, 'data/rds/origin_densities.rds')\nwrite_rds(destination_densities, 'data/rds/destination_densities.rds')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-data-from-rds",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-data-from-rds",
    "title": "Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore",
    "section": "Loading data from RDS",
    "text": "Loading data from RDS\nWe can use read_rds() to reload any saved RDS file\n\norigin &lt;- read_rds('data/rds/origin.rds')\ndestination &lt;- read_rds('data/rds/destination.rds')\nroad_sf &lt;- read_rds('data/rds/road_sf.rds')\nmpsz2019_sf &lt;- read_rds('data/rds/mpsz2019_sf.rds')\nsg_sf &lt;- read_rds('data/rds/sg_sf.rds')\norigin_densities &lt;- read_rds('data/rds/origin_densities.rds')\ndestination_densities &lt;- read_rds('data/rds/destination_densities.rds')\norigin_lixels &lt;- read_rds('data/rds/origin_lixels.rds')\ndestination_lixels &lt;- read_rds('data/rds/destination_lixels.rds')\norigin_samples &lt;- read_rds('data/rds/origin_samples.rds')\ndestination_samples &lt;- read_rds('data/rds/destination_samples.rds')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "href": "Take-home_Ex/Take-home_Ex02/data/geospatial/TAINAN_VILLAGE.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“TWD97”,DATUM[“Taiwan Datum 1997”,ELLIPSOID[“GRS 1980”,6378137,298.257222101,LENGTHUNIT[“metre”,1]]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“Taiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.”],BBOX[17.36,114.32,26.96,123.61]],ID[“EPSG”,3824]] +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs 27230 3824 EPSG:3824 TWD97 longlat EPSG:7019 true"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "Dengue Hemorrhagic Fever (in short dengue fever) is one of the most widespread mosquito-borne diseases in the most tropical and subtropical regions. It is an acute disease caused by dengue virus infection which is transmitted by female Aedes aegypti and Aedes albopictus mosquitoes. In 2015, Taiwan had recorded the most severe dengue fever outbreak with more than 43,000 dengue cases and 228 deaths. Since then, the annual reported dengue fever cases were maintained at the level of not more than 200 cases. However, in 2023, Taiwan recorded 26703 dengue fever cases. More than 25,000 cases were reported at Tainan City, and more than 80% of the reported dengue fever cases occurred in the month August-November 2023 and epidemiology week 31-50.\n\n\n\nAs a curious geospatial analytics green horn, you are interested to discover:\n\nif the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from space and space and time.\nIf the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.\n\nThe Task The specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer:\n\n\na study area layer in sf polygon features. It must be at village level and confined to the D01, D02, D04, D06, D07, D08, D32 and D39 counties of Tainan City, Taiwan.\na dengue fever layer within the study area in sf point features. The dengue fever cases should be confined to epidemiology week 31-50, 2023.\na derived dengue fever layer in spacetime s3 class of sfdep. It should contain, among many other useful information, a data field showing number of dengue fever cases by village and by epidemiology week.\nUsing the extracted data, perform global spatial autocorrelation analysis by using sfdep methods.\n\n\nUsing the extracted data, perform local spatial autocorrelation analysis by using sfdep methods.\nUsing the extracted data, perform emerging hotspot analysis by using sfdep methods.\nDescribe the spatial patterns revealed by the analysis above.\n\n\n\n\nFor the purpose of this take-home exercise, two data sets are provided, they are:\nTAIWAN_VILLAGE_2020, a geospatial data of village boundary of Taiwan. It is in ESRI shapefile format. The data is in Taiwan Geographic Coordinate System. (Source: Historical map data of the village boundary: TWD97 longitude and latitude)\nDengue_Daily.csv, an aspatial data of reported dengue cases in Taiwan since 1998. (Source: Dengue Daily Confirmed Cases Since 1998. Below are selected fields that are useful for this study:\n\n發病日: Onset date\n最小統計區中心點X: x-coordinate\n最小統計區中心點Y: y-coordinate Both data sets have been uploaded on eLearn. Students are required to download them from eLearn."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "Dengue Hemorrhagic Fever (in short dengue fever) is one of the most widespread mosquito-borne diseases in the most tropical and subtropical regions. It is an acute disease caused by dengue virus infection which is transmitted by female Aedes aegypti and Aedes albopictus mosquitoes. In 2015, Taiwan had recorded the most severe dengue fever outbreak with more than 43,000 dengue cases and 228 deaths. Since then, the annual reported dengue fever cases were maintained at the level of not more than 200 cases. However, in 2023, Taiwan recorded 26703 dengue fever cases. More than 25,000 cases were reported at Tainan City, and more than 80% of the reported dengue fever cases occurred in the month August-November 2023 and epidemiology week 31-50."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "As a curious geospatial analytics green horn, you are interested to discover:\n\nif the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from space and space and time.\nIf the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.\n\nThe Task The specific tasks of this take-home exercise are as follows:\n\nUsing appropriate function of sf and tidyverse, preparing the following geospatial data layer:\n\n\na study area layer in sf polygon features. It must be at village level and confined to the D01, D02, D04, D06, D07, D08, D32 and D39 counties of Tainan City, Taiwan.\na dengue fever layer within the study area in sf point features. The dengue fever cases should be confined to epidemiology week 31-50, 2023.\na derived dengue fever layer in spacetime s3 class of sfdep. It should contain, among many other useful information, a data field showing number of dengue fever cases by village and by epidemiology week.\nUsing the extracted data, perform global spatial autocorrelation analysis by using sfdep methods.\n\n\nUsing the extracted data, perform local spatial autocorrelation analysis by using sfdep methods.\nUsing the extracted data, perform emerging hotspot analysis by using sfdep methods.\nDescribe the spatial patterns revealed by the analysis above."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "",
    "text": "For the purpose of this take-home exercise, two data sets are provided, they are:\nTAIWAN_VILLAGE_2020, a geospatial data of village boundary of Taiwan. It is in ESRI shapefile format. The data is in Taiwan Geographic Coordinate System. (Source: Historical map data of the village boundary: TWD97 longitude and latitude)\nDengue_Daily.csv, an aspatial data of reported dengue cases in Taiwan since 1998. (Source: Dengue Daily Confirmed Cases Since 1998. Below are selected fields that are useful for this study:\n\n發病日: Onset date\n最小統計區中心點X: x-coordinate\n最小統計區中心點Y: y-coordinate Both data sets have been uploaded on eLearn. Students are required to download them from eLearn."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-packages",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Loading Packages",
    "text": "Loading Packages\nWe can use this code chunk to load the required packages"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-data-and-data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-data-and-data-wrangling",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Loading Data and Data Wrangling",
    "text": "Loading Data and Data Wrangling\n\nAspatial Data\nWe can load the dengue_daily data with the code chunk below. Since we are only stuyding cases from week 31-50, we can use filter() to get the dates from 31 July to 17 December, which is week 31-50\n\n\nRows: 25,480\nColumns: 26\n$ 發病日             &lt;date&gt; 2023-07-31, 2023-07-31, 2023-07-31, 2023-07-31, 20…\n$ 個案研判日         &lt;chr&gt; \"2023/07/31\", \"2023/07/31\", \"2023/07/31\", \"2023/07/…\n$ 通報日             &lt;date&gt; 2023-07-31, 2023-07-31, 2023-07-31, 2023-07-31, 20…\n$ 性別               &lt;chr&gt; \"女\", \"男\", \"男\", \"男\", \"男\", \"男\", \"女\", \"女\", \"男…\n$ 年齡層             &lt;chr&gt; \"30-34\", \"55-59\", \"5-9\", \"70+\", \"55-59\", \"30-34\", \"…\n$ 居住縣市           &lt;chr&gt; \"台南市\", \"台南市\", \"台南市\", \"台南市\", \"台南市\", \"…\n$ 居住鄉鎮           &lt;chr&gt; \"永康區\", \"東區\", \"永康區\", \"仁德區\", \"永康區\", \"古…\n$ 居住村里           &lt;chr&gt; \"埔園里\", \"大智里\", \"五王里\", \"成功里\", \"中興里\", \"…\n$ 最小統計區         &lt;chr&gt; \"A6731-0201-00\", \"A6732-1040-00\", \"A6731-0574-00\", …\n$ 最小統計區中心點X  &lt;chr&gt; \"120.253752333\", \"120.232374917\", \"120.235733496\", …\n$ 最小統計區中心點Y  &lt;chr&gt; \"23.031699814\", \"22.962366283\", \"23.013083716\", \"22…\n$ 一級統計區         &lt;chr&gt; \"A6731-16-006\", \"A6732-64-001\", \"A6731-42-008\", \"A6…\n$ 二級統計區         &lt;chr&gt; \"A6731-16\", \"A6732-64\", \"A6731-42\", \"A6727-10\", \"A6…\n$ 感染縣市           &lt;chr&gt; \"台南市\", \"台南市\", \"台南市\", \"台南市\", \"台南市\", \"…\n$ 感染鄉鎮           &lt;chr&gt; \"永康區\", \"東區\", \"永康區\", \"仁德區\", \"永康區\", \"古…\n$ 感染村里           &lt;chr&gt; \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"No…\n$ 是否境外移入       &lt;chr&gt; \"否\", \"否\", \"否\", \"否\", \"否\", \"否\", \"否\", \"否\", \"否…\n$ 感染國家           &lt;chr&gt; \"中華民國\", \"中華民國\", \"中華民國\", \"中華民國\", \"中…\n$ 確定病例數         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ 居住村里代碼       &lt;chr&gt; \"6703100-004\", \"6703200-003\", \"6703100-001\", \"67027…\n$ 感染村里代碼       &lt;chr&gt; \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"No…\n$ 血清型             &lt;chr&gt; \"None\", \"None\", \"None\", \"None\", \"第一型\", \"第一型\",…\n$ 內政部居住縣市代碼 &lt;chr&gt; \"67\", \"67\", \"67\", \"67\", \"67\", \"10009\", \"67\", \"67\", …\n$ 內政部居住鄉鎮代碼 &lt;chr&gt; \"6703100\", \"6703200\", \"6703100\", \"6702700\", \"670310…\n$ 內政部感染縣市代碼 &lt;chr&gt; \"67\", \"67\", \"67\", \"67\", \"67\", \"10009\", \"67\", \"67\", …\n$ 內政部感染鄉鎮代碼 &lt;chr&gt; \"6703100\", \"6703200\", \"6703100\", \"6702700\", \"670310…\n\n\nIn order to save up on computational resources and make it more readable, we will only take up the three fields mentioned above and rename it to English\n\n\nRows: 25,480\nColumns: 3\n$ OnsetDate    &lt;date&gt; 2023-07-31, 2023-07-31, 2023-07-31, 2023-07-31, 2023-07-…\n$ X_Coordinate &lt;chr&gt; \"120.253752333\", \"120.232374917\", \"120.235733496\", \"120.2…\n$ Y_Coordinate &lt;chr&gt; \"23.031699814\", \"22.962366283\", \"23.013083716\", \"22.95747…\n\n\nSince the coordinates are still in chr format, we need to convert it to numeric first\n\n\n   OnsetDate           X_Coordinate    Y_Coordinate  \n Min.   :2023-07-31   Min.   :118.3   Min.   :21.99  \n 1st Qu.:2023-09-11   1st Qu.:120.2   1st Qu.:22.97  \n Median :2023-10-01   Median :120.2   Median :22.99  \n Mean   :2023-10-03   Mean   :120.3   Mean   :23.01  \n 3rd Qu.:2023-10-26   3rd Qu.:120.3   3rd Qu.:23.02  \n Max.   :2023-12-17   Max.   :121.9   Max.   :25.20  \n                      NA's   :14      NA's   :14     \n\n\nSince the data still have some missing values, let’s clean that up first\n\n\n   OnsetDate           X_Coordinate    Y_Coordinate  \n Min.   :2023-07-31   Min.   :118.3   Min.   :21.99  \n 1st Qu.:2023-09-11   1st Qu.:120.2   1st Qu.:22.97  \n Median :2023-10-01   Median :120.2   Median :22.99  \n Mean   :2023-10-03   Mean   :120.3   Mean   :23.01  \n 3rd Qu.:2023-10-26   3rd Qu.:120.3   3rd Qu.:23.02  \n Max.   :2023-12-17   Max.   :121.9   Max.   :25.20  \n\n\nAfter the data is clean, we can convert it into sf. Remember to convert the crs to TWD97 (crs=3824)\n\n\nRows: 25,466\nColumns: 2\n$ OnsetDate &lt;date&gt; 2023-07-31, 2023-07-31, 2023-07-31, 2023-07-31, 2023-07-31,…\n$ geometry  &lt;POINT [°]&gt; POINT (120.2538 23.0317), POINT (120.2324 22.96237), P…\n\n\n\n\nGeospatial Data\nWe can use st_read() to load the geospatial data, with an additional filter to get only the counties mentioned above. We can plot it to get a better understanding of the data\n\n\nReading layer `TAINAN_VILLAGE' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 649 features and 10 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0269 ymin: 22.88751 xmax: 120.6563 ymax: 23.41374\nGeodetic CRS:  TWD97\n\n\nRows: 258\nColumns: 11\n$ VILLCODE   &lt;chr&gt; \"67000350032\", \"67000270011\", \"67000370005\", \"67000330004\",…\n$ COUNTYNAME &lt;chr&gt; \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\", \"臺南市\",…\n$ TOWNNAME   &lt;chr&gt; \"安南區\", \"仁德區\", \"中西區\", \"南區\", \"安南區\", \"安南區\", \"…\n$ VILLNAME   &lt;chr&gt; \"青草里\", \"保安里\", \"赤嵌里\", \"大成里\", \"城北里\", \"城南里\",…\n$ VILLENG    &lt;chr&gt; \"Qingcao Vil.\", \"Bao'an Vil.\", \"Chihkan Vil.\", \"Dacheng Vil…\n$ COUNTYID   &lt;chr&gt; \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\", \"D\",…\n$ COUNTYCODE &lt;chr&gt; \"67000\", \"67000\", \"67000\", \"67000\", \"67000\", \"67000\", \"6700…\n$ TOWNID     &lt;chr&gt; \"D06\", \"D32\", \"D08\", \"D02\", \"D06\", \"D06\", \"D08\", \"D06\", \"D0…\n$ TOWNCODE   &lt;chr&gt; \"67000350\", \"67000270\", \"67000370\", \"67000330\", \"67000350\",…\n$ NOTE       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ geometry   &lt;POLYGON [°]&gt; POLYGON ((120.1176 23.08387..., POLYGON ((120.2304 …\n\n\n\n\n\n\n\nData Wrangling\nNow we join the two data with st_join. Here, we use EpiWeek to group together cases in the same week. Don’t forget to handle missing values as well\n\n\n   OnsetDate                   geometry       VILLCODE        \n Min.   :2023-07-31   POINT        :18800   Length:18800      \n 1st Qu.:2023-09-09   epsg:3824    :    0   Class :character  \n Median :2023-09-27   +proj=long...:    0   Mode  :character  \n Mean   :2023-09-28                                           \n 3rd Qu.:2023-10-17                                           \n Max.   :2023-12-17                                           \n  COUNTYNAME          TOWNNAME           VILLNAME           VILLENG         \n Length:18800       Length:18800       Length:18800       Length:18800      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n   COUNTYID          COUNTYCODE           TOWNID            TOWNCODE        \n Length:18800       Length:18800       Length:18800       Length:18800      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    EpiWeek     \n Min.   :31.00  \n 1st Qu.:36.00  \n Median :39.00  \n Mean   :39.06  \n 3rd Qu.:42.00  \n Max.   :50.00  \n\n\nAfter joining, we can make a new sf data to store the summary of how many cases appear in a specific village in a specific week.\n\n\n   VILLCODE            EpiWeek      NumberOfCases            geometry   \n Length:3514        Min.   :31.00   Min.   : 1.00   MULTIPOINT   :2523  \n Class :character   1st Qu.:36.00   1st Qu.: 1.00   POINT        : 991  \n Mode  :character   Median :40.00   Median : 3.00   epsg:3824    :   0  \n                    Mean   :39.87   Mean   : 5.35   +proj=long...:   0  \n                    3rd Qu.:44.00   3rd Qu.: 7.00                       \n                    Max.   :50.00   Max.   :56.00                       \n\n\nNow, to get the geometry of the villages, we can combine it with the tainan dataset. Before combining, we need to convert dengue_summary to df by dropping the geometry column. But, note that this df data does not contain rows where there are no case at all in a particular village in a particular week. To fix that, we can use complete() with the parameters in the chunk below. What it does is that it will automatically add a row for every combination of VILLCODE and EpiWeek possible, and if there are no cases for that particular combination, the fill argument will add a 0 instead of NA in the NumberOfCases column\nThen, we can use left_join() to join the datasets based on the same “VILLCODE”. We can use select() to retrieve only the columns we need. Remember to turn the joined data back to sf\nLet’s check the CRS of the new sf to make sure that its in the same reference system\n\n\nCoordinate Reference System:\n  User input: TWD97 \n  wkt:\nGEOGCRS[\"TWD97\",\n    DATUM[\"Taiwan Datum 1997\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Taiwan, Republic of China - onshore and offshore - Taiwan Island, Penghu (Pescadores) Islands.\"],\n        BBOX[17.36,114.32,26.96,123.61]],\n    ID[\"EPSG\",3824]]\n\n\n\n\nCreating Spatiotemporal Layer\nTo create a spatiotemporal layer, we can use as_spacetime() for the dengue_summary_sf, with VILLCODE for the spatial column and EpiWeek to represent the temporal column\nTo see the data, we can use activate() with ‘data’ for the second argument\n\n\n# A tibble: 5,140 × 3\n   VILLCODE    EpiWeek NumberOfCases\n * &lt;chr&gt;         &lt;dbl&gt;         &lt;int&gt;\n 1 67000270001      31             0\n 2 67000270001      32             0\n 3 67000270001      33             1\n 4 67000270001      34             1\n 5 67000270001      35             2\n 6 67000270001      36             3\n 7 67000270001      37             5\n 8 67000270001      38             4\n 9 67000270001      39             3\n10 67000270001      40             2\n# ℹ 5,130 more rows\n\n\nOn the other hand, the geometry values can be seen with activate() also, only with ‘geometry’ for the second argument\n\n\nSimple feature collection with 257 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 120.0627 ymin: 22.89401 xmax: 120.2925 ymax: 23.09144\nGeodetic CRS:  TWD97\n# A tibble: 257 × 2\n   VILLCODE                                                             geometry\n * &lt;chr&gt;                                                           &lt;POLYGON [°]&gt;\n 1 67000270001 ((120.2672 22.99653, 120.2673 22.99616, 120.2675 22.9958, 120.26…\n 2 67000270002 ((120.266 22.99104, 120.266 22.99096, 120.2659 22.99083, 120.265…\n 3 67000270003 ((120.2492 22.98265, 120.2497 22.9826, 120.2504 22.98251, 120.25…\n 4 67000270004 ((120.2391 22.98008, 120.2393 22.98001, 120.2394 22.97996, 120.2…\n 5 67000270005 ((120.2578 22.97427, 120.2584 22.97398, 120.2591 22.97356, 120.2…\n 6 67000270006 ((120.2713 22.96793, 120.2712 22.96777, 120.2712 22.96766, 120.2…\n 7 67000270007 ((120.2408 22.959, 120.2422 22.95846, 120.2435 22.95791, 120.244…\n 8 67000270008 ((120.2701 22.94837, 120.2701 22.94824, 120.27 22.94819, 120.27 …\n 9 67000270011 ((120.2304 22.93544, 120.2306 22.93519, 120.2319 22.93271, 120.2…\n10 67000270012 ((120.2251 22.96159, 120.2256 22.96149, 120.2261 22.9614, 120.22…\n# ℹ 247 more rows\n\n\nBefore using the spacetime layer in further computations, we can check if it is a proper cube\n\n\n[1] TRUE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-data",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Visualizing Data",
    "text": "Visualizing Data\nNow, we are plotting a choropleth to see the distribution of cases using tmap"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-contiguity-spatial-weights",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-contiguity-spatial-weights",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The code chunk below will use sfdep methods to derive the contiguity weights\n\n\nNeighbour list object:\nNumber of regions: 5140 \nNumber of nonzero links: 704060 \nPercentage nonzero weights: 2.664915 \nAverage number of links: 136.9767"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-global-moran-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-global-moran-i",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Computing Global Moran’ I",
    "text": "Computing Global Moran’ I\nWe can use global_moran() to compute the Global Moran’ I value, which will return a tibble as an output\n\n\nList of 2\n $ I: num 0.15\n $ K: num 17.1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-moran-i-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-moran-i-test",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Global Moran’ I Test",
    "text": "Global Moran’ I Test\nWe will use global_moran_test() to perform the Moran’ I test\n\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 87.954, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     1.497162e-01     -1.945904e-04      2.905083e-06"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-morani-permutation-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#global-morani-permutation-test",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Global Moran’I Permutation Test",
    "text": "Global Moran’I Permutation Test\nIn a realistic setting, we can use Monte Carlo simulation to perform the test. For reproducibility, we can set the seed in the start\n\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.14972, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe statistical report above show that the p-value is smaller than alpha value of 0.05. Hence, we have enough statistical evidence to reject the null hypothesis that the spatial distribution of cases resemble random distribution (i.e. independent from spatial). Because the Moran’s I statistics is greater than 0, We can infer that the spatial distribution shows sign of clustering."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-moran-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-moran-i",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Computing Local Moran’ I",
    "text": "Computing Local Moran’ I\nTo compute Local Moran’ I, we can use local_moran() instead"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-p-value-of-local-moran-i",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-p-value-of-local-moran-i",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Visualizing p-value of Local Moran’ I",
    "text": "Visualizing p-value of Local Moran’ I\ntmap can also be used to plot the p-value in the “p_ii_sim” column"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-lisa-map",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-lisa-map",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Visualizing LISA Map",
    "text": "Visualizing LISA Map\nLISA map is a categorical map showing outliers and clusters. In lisa sf data.frame, we can find three fields contain the LISA categories. They are mean, median and pysal. In general, classification in mean will be used as shown in the code chunk below.\n\n\n\n\n\nHere is an explanation of the different categories:\nHigh-High (HH): The location has a high value and is surrounded by neighbors with high values. Low-Low (LL): The location has a low value and is surrounded by neighbors with low values. Low-High (LH): The location has a low value but is surrounded by neighbors with high values. High-Low (HL): The location has a high value but is surrounded by neighbors with low values."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#derive-spatial-weights",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#derive-spatial-weights",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Derive Spatial Weights",
    "text": "Derive Spatial Weights\nIn EHSA,we will use the space-time cube we created before. First, we derive distance weights using the code chunk below"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-gi",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-gi",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Computing Gi*",
    "text": "Computing Gi*\nWe can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by week and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mann-kendall-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mann-kendall-test",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Mann-Kendall Test",
    "text": "Mann-Kendall Test\nWith these Gi* measuers, we can perform a Mann-Kendall test to identify a trend. For this example, we can look at VILLCODE 67000270001\nAnd plot the result using ggplot\n\n\n\n\n\n\n\n# A tibble: 1 × 5\n    tau    sl     S     D  varS\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.105 0.538    20  190.   950\n\n\nThe cbg tells us that sl (p-value) is 0.5376031. This shows that there is a significant trend\nNow we can use group_by to perform the test for every location"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#arranging-to-show-significant-emerging-hotcold-spots",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#arranging-to-show-significant-emerging-hotcold-spots",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Arranging To Show Significant Emerging Hot/Cold Spots",
    "text": "Arranging To Show Significant Emerging Hot/Cold Spots\nUse the code chunk to arrange to show significant emerging hot/cold spots"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-emerging-hotspot-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#performing-emerging-hotspot-analysis",
    "title": "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan",
    "section": "Performing Emerging HotSpot Analysis",
    "text": "Performing Emerging HotSpot Analysis\nNext, we can use emerging_hotspot_analysis() to perform EHSA. It takes in a spacetime object x, variable of interest y, number of time lags (set by default to 1), and nsim = 99 to indicate that there will be 99 simulations\n\nVisualizing the Distribution of EHSA Classes\nWe can use ggplot to see the distribution of EHSA classes\n\n\n\n\n\n\n\nVisualizing EHSA\nWe will start on how to visualize the geographic distribution EHSA classes. First, we join the two tables together with left_join\nNext, we can make a choropleth map"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "",
    "text": "We are using Spatial Point Pattern Analysis to answer these questions: 1. Are the locations of room rentals in Jakarta randomly distributed? 2. If not randomly distributed, where are the locations with high concentration of room rentals?"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#jakarta-data-loading",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#jakarta-data-loading",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "Jakarta Data Loading",
    "text": "Jakarta Data Loading\n\n\nReading layer `jakarta' from data source \n  `C:\\Users\\yozaf\\SMUY3S2\\Geospatial\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\rds' \n  using driver `ESRI Shapefile'\nSimple feature collection with 260 features and 27 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.6862 ymin: -6.370731 xmax: 106.9733 ymax: -6.088227\nGeodetic CRS:  WGS 84 + EGM2008 height\n\n\nNote that the data is in a WGS 84 + EGM2008 height CRS. We can convert it to WGS84 with the chunk below\nWe can use qtm() to get a simple map of the jakarta data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#mamikos-data-loading",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#mamikos-data-loading",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "Mamikos Data Loading",
    "text": "Mamikos Data Loading\n\n\n      _id           price_monthly         latitude        longitude    \n Min.   : 1728989   Min.   :  350000   Min.   :-6.286   Min.   :106.7  \n 1st Qu.:32773220   1st Qu.: 1000000   1st Qu.:-6.239   1st Qu.:106.8  \n Median :55360905   Median : 1600000   Median :-6.202   Median :106.8  \n Mean   :54976650   Mean   : 1868027   Mean   :-6.207   Mean   :106.8  \n 3rd Qu.:77177521   3rd Qu.: 2400000   3rd Qu.:-6.178   3rd Qu.:106.9  \n Max.   :99992091   Max.   :15000000   Max.   :-6.130   Max.   :106.9  \n                                                                       \n     gender       area_city_keyword  area_subdistrict       status      \n Min.   :0.0000   Length:8969        Length:8969        Min.   :0.0000  \n 1st Qu.:0.0000   Class :character   Class :character   1st Qu.:0.0000  \n Median :1.0000   Mode  :character   Mode  :character   Median :0.0000  \n Mean   :0.8145                                         Mean   :0.6262  \n 3rd Qu.:2.0000                                         3rd Qu.:2.0000  \n Max.   :2.0000                                         Max.   :2.0000  \n                                                                        \n     size             fac_room          fac_share           fac_bath        \n Length:8969        Length:8969        Length:8969        Length:8969       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   fac_near           fac_park           kos_rule          fac_price        \n Length:8969        Length:8969        Length:8969        Length:8969       \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n owner_user_id     building_year  is_singgahsini   is_apik       \n Min.   :   6350   Min.   :   0   Mode :logical   Mode :logical  \n 1st Qu.:1338529   1st Qu.:2015   FALSE:8499      FALSE:8853     \n Median :3475312   Median :2019   TRUE :470       TRUE :116      \n Mean   :3535335   Mean   :1991                                  \n 3rd Qu.:5480051   3rd Qu.:2021                                  \n Max.   :8163159   Max.   :2024                                  \n NA's   :5         NA's   :984                                   \n  is_elite       number_success_owner_trx number_success_kos_trx\n Mode :logical   Min.   :    0.0          Min.   :  0.000       \n FALSE:8969      1st Qu.:    0.0          1st Qu.:  0.000       \n                 Median :    0.0          Median :  0.000       \n                 Mean   :  688.7          Mean   :  3.587       \n                 3rd Qu.:    3.0          3rd Qu.:  3.000       \n                 Max.   :10961.0          Max.   :241.000       \n                                                                \n     url           \n Length:8969       \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nNote that the mamikos data has its location in the latitude and longitude columns, which we can convert to geometry in an sf dataframe\n\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nWe can plot the map with tmap"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#data-wrangling",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nConverting to ppp\nSince spatstat requires data in ppp object form, we can use as.ppp to directly convert sf to ppp. However, we have to change the CRS to 23833 or DGN95, which is Indonesia’s CRS System, as ppp file requires projected geometries (not WGS84)\n\n\nChecking for duplicates\n\n\n[1] FALSE\n\n\nSince there are no duplicates, we can go on to the next step\n\n\nCreating owin object\nWe can make an owin object to confine our analysis to only Jakarta\n\n\n\n\n\n\n\nCombining Jakarta and Mamikos Data\nWe will extract only rental rooms within the owin object"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#deriving-kernel-density-estimation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#deriving-kernel-density-estimation",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "Deriving Kernel Density Estimation",
    "text": "Deriving Kernel Density Estimation\nWe are using adaptive bandwidth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConverting output to grid\n\n\n\n\n\n\n\n\n\n\nConverting grid to raster\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 248.5865, 245.3833  (x, y)\nextent     : 552807.9, 584626.9, 794365.4, 825774.4  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -7.371997e-20, 0.0006103475  (min, max)\n\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 248.5865, 245.3833  (x, y)\nextent     : 552807.9, 584626.9, 794365.4, 825774.4  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : 5.655212e-17, 0.001577487  (min, max)\n\n\nNote that the CRS is NA, so we can assign the CRS by ourselves"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#visualizing-output-in-tmap",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#visualizing-output-in-tmap",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "Visualizing Output in Tmap",
    "text": "Visualizing Output in Tmap\nFor the rooms\n\n\n\n\n\nFor the schools\n\n\n\n\n\nOverlay of both"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#user-inputs-sidebar",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#user-inputs-sidebar",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "User Inputs Sidebar",
    "text": "User Inputs Sidebar\nWhen implementing this to the Shiny App, we can make it dynamic by implementing this in our sidebar:\n\nImplementing input for cities: For analyzing Kernel Density Estimates with a specific city, instead of the whole DKI Jakarta, we can use a select input where users can choose which city they want, or Jakarta as a whole\nEducational Institutions: If users have any requirements regarding the educational institutions displayed (e.g: they only want to analyze nearby universities or wants to exclude primary schools), they can use a checkbox to select which levels will be analyzed.\nImplementing Kernel methods. Users can choose which kernel methods they want for the KDE analysis using a dropdown"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#main-panel",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03_KDE.html#main-panel",
    "title": "1st Order Spatial Point Pattern Analysis: Kernel Density Estimation",
    "section": "Main Panel",
    "text": "Main Panel\nThe main panel will be displaying the KDE map, with three separate tabs to display:\n\nThe combined overlay of both Mamikos rooms and schools\nOnly the Mamikos rooms\nOnly schools\n\n\n\n\nStoryboard"
  }
]